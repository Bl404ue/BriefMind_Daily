标题,中文标题,领域分类,研究机构,PDF链接,论文链接,简明摘要,Upvote数
"Advances and Challenges in Foundation Agents: From Brain-Inspired
  Intelligence to Evolutionary, Collaborative, and Safe Systems",基础智能体的进展与挑战：从脑启发智能到进化、协作和安全系统,Agent,Other,https://arxiv.org/pdf/2504.01990,https://huggingface.co/papers/2504.01990,这篇论文探讨了大型语言模型（LLMs）带来的智能体设计与应用的进展与挑战。作者提出了一种模块化的、受脑科学启发的智能体架构，涵盖了认知、感知和操作模块，揭示了与人类大脑功能的对应关系。论文分为四个部分：首先，分析智能体的基础模块；其次，探讨自我增强与适应性进化机制；第三，研究协作与进化的多智能体系统；最后，强调构建安全、可靠和有益的AI系统的重要性。该研究为智能体的持续改进和实际应用提供了全面的视角。,54
"Envisioning Beyond the Pixels: Benchmarking Reasoning-Informed Visual
  Editing",超越像素的构想：基于推理的视觉编辑基准测试,Multimodal LLM,Shanghai AI Lab,https://arxiv.org/pdf/2504.02826,https://huggingface.co/papers/2504.02826,本论文提出了RISEBench，这是第一个用于评估推理驱动的视觉编辑（RISE）的基准，旨在解决大型多模态模型（LMMs）在复杂指令执行、外观一致性保持和灵活输入格式支持方面的挑战。RISEBench聚焦于四种推理类型：时间、因果、空间和逻辑推理，提供高质量的测试案例和评估框架。实验表明，尽管GPT-4o-Native在性能上优于其他模型，但在逻辑推理任务上仍存在不足。RISEBench为推理意识的视觉编辑提供了基础性见解，并为未来研究奠定了基础。代码和数据将在GitHub上发布。,38
"GPT-ImgEval: A Comprehensive Benchmark for Diagnosing GPT4o in Image
  Generation",GPT-ImgEval：用于诊断GPT4o在图像生成中的综合基准,Multimodal LLM,Other,https://arxiv.org/pdf/2504.02782,https://huggingface.co/papers/2504.02782,本论文介绍了GPT-ImgEval，这是一个针对OpenAI的GPT-4o模型在图像生成和编辑方面性能的综合评估基准。研究从生成质量、编辑能力和语义合成三个维度对GPT-4o进行了定量和定性分析，结果显示其在图像生成控制和输出质量上显著优于现有方法。此外，论文探讨了GPT-4o的架构，提出其可能结合了自回归和扩散解码的特点。研究还识别了模型的局限性和常见的合成伪影，并与Gemini 2.0 Flash进行了多轮图像编辑的比较。此工作旨在为未来研究提供可靠的基准，促进图像生成领域的创新。,27
"Rethinking RL Scaling for Vision Language Models: A Transparent,
  From-Scratch Framework and Comprehensive Evaluation Scheme",重新思考视觉语言模型的强化学习扩展：一个透明的从零开始框架和全面的评估方案,Multimodal LLM,Other,https://arxiv.org/pdf/2504.02587,https://huggingface.co/papers/2504.02587,本论文提出了一种透明且从零开始的强化学习（RL）框架，旨在提升视觉语言模型（VLM）的推理能力。现有的RL应用往往依赖复杂的工程框架，限制了可重复性和可访问性，因此本研究提供了一个简洁的四步流程，并在多个模型和数据集上进行了验证。同时，论文还提出了标准化的评估方案，以评估训练动态和反思行为。实验证明，RL在泛化能力上优于监督微调（SFT），并指出响应长度对随机种子敏感。这一研究为RL在VLM领域的广泛应用奠定了可重复的基础。,17
SkyReels-A2: Compose Anything in Video Diffusion Transformers,SkyReels-A2：在视频扩散变换器中合成任意内容,Diffusion Model,Other,https://arxiv.org/pdf/2504.02436,https://huggingface.co/papers/2504.02436,论文介绍了SkyReels-A2，一个可控的视频生成框架，能够根据文本提示将任意视觉元素（如角色、物体、背景）组装成合成视频，同时保持与每个元素的参考图像的一致性。该框架面临的主要挑战包括保留元素的真实性、确保场景的连贯性和实现自然输出。为此，研究者设计了一个数据管道构建训练所需的提示-参考-视频三元组，并提出了一个新的图像-文本联合嵌入模型，以平衡元素一致性和全局连贯性。SkyReels-A2是首个开源的E2V生成模型，表现优于许多闭源商业模型，预计将推动创意应用的发展。,16
"ShortV: Efficient Multimodal Large Language Models by Freezing Visual
  Tokens in Ineffective Layers",ShortV：通过冻结无效层中的视觉标记实现高效的多模态大语言模型,Multimodal LLM,Other,https://arxiv.org/pdf/2504.00502,https://huggingface.co/papers/2504.00502,"本文提出了一种名为ShortV的方法，以提高多模态大型语言模型（MLLMs）的计算效率。通过引入层贡献（Layer Contribution, LC）指标，作者评估了各层对视觉和文本标记的影响，发现许多层在处理视觉标记时贡献有限。ShortV通过冻结这些无效层中的视觉标记更新，成功减少了约60%的计算负担，并在LLaVA-NeXT-13B模型上实现了50%的FLOPs减少，同时保持了优异的性能。这一方法无需训练，且与现有的标记剪枝技术兼容，为多模态模型的高效运行提供了新思路。",10
"Audio-visual Controlled Video Diffusion with Masked Selective State
  Spaces Modeling for Natural Talking Head Generation",基于音视频控制的扩散模型与掩码选择状态空间建模用于自然人头生成,Diffusion Model,"Tencent, THU",https://arxiv.org/pdf/2504.02542,https://huggingface.co/papers/2504.02542,本文介绍了ACTalker，一个创新的视频扩散框架，旨在生成自然的虚拟人头视频，支持多种信号和单一信号的控制。通过设计并行的mamba结构，ACTalker能够利用不同的驱动信号独立控制面部特定区域，并通过门控机制实现灵活控制。此外，引入的mask-drop策略确保了不同信号之间的独立性，避免了控制冲突。实验结果表明，该方法能够生成自然逼真的面部视频，且成功整合多种驱动信号，提升了虚拟头像在人机交互中的实用性。,8
ZClip: Adaptive Spike Mitigation for LLM Pre-Training,ZClip: 大语言模型预训练的自适应尖峰缓解,LLM,Other,https://arxiv.org/pdf/2504.02507,https://huggingface.co/papers/2504.02507,本文提出了ZClip，一种自适应梯度裁剪算法，旨在解决大规模语言模型训练中的梯度不稳定和损失尖峰问题。传统的固定阈值裁剪方法无法有效应对这些挑战，常导致训练效率低下和频繁的人工干预。ZClip通过动态调整裁剪阈值，基于梯度范数的统计特性，主动适应训练动态，利用z-score异常检测识别和缓解大幅度梯度尖峰，从而防止恶性损失尖峰的发生，同时不干扰模型收敛。该方法为提升大语言模型的训练稳定性提供了新的解决方案。,7
Efficient Model Selection for Time Series Forecasting via LLMs,通过大语言模型进行时间序列预测的高效模型选择,LLM,Other,https://arxiv.org/pdf/2504.02119,https://huggingface.co/papers/2504.02119,本文提出了一种利用大型语言模型（LLMs）进行时间序列预测模型选择的新方法，旨在替代传统的、耗时的性能评估过程。通过借助LLMs的知识和推理能力，研究者们消除了对预构建性能矩阵的依赖，从而显著降低了计算开销。实验结果表明，该方法在效率和准确性上均优于传统的元学习技术和启发式基线。这一研究展示了LLMs在提高时间序列预测模型选择效率方面的潜力，具有重要的应用价值。,4
Instruction-Guided Autoregressive Neural Network Parameter Generation,基于指令的自回归神经网络参数生成,Diffusion Model,Other,https://arxiv.org/pdf/2504.02012,https://huggingface.co/papers/2504.02012,本论文提出了一种名为IGPG（Instruction-Guided Parameter Generation）的自回归框架，用于根据任务描述和网络架构生成神经网络参数。与现有方法相比，IGPG克服了扩展性差、处理网络深度的灵活性不足及参数生成不连贯等问题。通过结合向量量化变分自编码器（VQ-VAE）和自回归模型，IGPG能够在多个任务和架构之间统一参数合成，确保层间一致性。大量实验表明，IGPG在多个视觉数据集上表现出色，具有较强的适应性和效率，展示了其在预训练权重检索、模型选择和快速任务特定微调中的潜力。,4
"GenPRM: Scaling Test-Time Compute of Process Reward Models via
  Generative Reasoning",GenPRM：通过生成推理扩展过程奖励模型的测试时间计算,LLM,"Shanghai AI Lab, THU",https://arxiv.org/pdf/2504.00891,https://huggingface.co/papers/2504.00891,本论文提出了一种新型的生成式过程奖励模型GenPRM，旨在解决现有过程奖励模型（PRMs）在测试时计算能力、监督能力和泛化能力方面的局限。GenPRM通过显式的链式思维推理和代码验证，提供每个推理步骤的判断，并引入相对进度估计（RPE）和理由合成框架以获取高质量的监督标签和推理数据。实验结果表明，GenPRM在ProcessBench和数学推理任务中显著优于先前的PRMs，并在测试时计算方面表现出色，成为优化策略模型的有效评估工具。这项研究为过程监督建立了新的范式，推动了PRMs与LLMs的融合。,3
Scaling Laws in Scientific Discovery with AI and Robot Scientists,利用人工智能和机器人科学家的科学发现中的规模法则,Embodied AI,Other,https://arxiv.org/pdf/2503.22444,https://huggingface.co/papers/2503.22444,本文提出了一个自主通用科学家（AGS）的概念，结合了人工智能和机器人技术，旨在自动化整个科学研究生命周期。现有的科学实践面临时间和资源的限制，而AGS系统能够在文献回顾、假设生成、实验和论文撰写等各个阶段进行动态互动，促进跨学科知识的整合。随着这些自主系统的不断集成，作者假设科学发现可能遵循新的规模法则，受制于自主系统的数量和能力。这一创新可能会显著提高科学研究的效率，推动科学进步，突破当前的限制。,3
Scaling Analysis of Interleaved Speech-Text Language Models,交错语音-文本语言模型的规模分析,LLM,Other,https://arxiv.org/pdf/2504.02398,https://huggingface.co/papers/2504.02398,本论文探讨了交错语音-文本语言模型（SLM）的扩展性分析，提出交错SLM在计算资源和数据需求方面比无文本SLM更高效。研究表明，交错SLM在知识转移方面表现出色，能够更有效地利用计算预算，尤其是在增加模型规模时。通过对多种模型的训练和分析，结果显示，交错SLM在语音语义指标上与领先模型的性能相当，但所需的计算和数据更少。此外，论文还探讨了合成数据和文本模型家族在提升模型潜力中的作用。研究成果和模型已开源，供进一步研究使用。,2
"Sparse Autoencoders Learn Monosemantic Features in Vision-Language
  Models",稀疏自编码器在视觉-语言模型中学习单义特征,Multimodal LLM,Other,https://arxiv.org/pdf/2504.02821,https://huggingface.co/papers/2504.02821,本论文探讨了稀疏自编码器（SAEs）在视觉-语言模型（VLMs）中的应用，特别是对CLIP模型的影响。研究表明，SAEs能够显著提高单义性特征的学习，使得神经元的表示更具解释性和可控性。通过引入一个全面的评估框架，作者展示了SAEs如何在不修改基础模型的情况下，直接引导多模态大语言模型（如LLaVA）的输出。这一发现强调了SAEs作为无监督方法在提升VLMs可解释性和控制能力方面的实用性与有效性。,2
Interpreting Emergent Planning in Model-Free Reinforcement Learning,无模型强化学习中的新兴规划解释,Agent,Other,https://arxiv.org/pdf/2504.01871,https://huggingface.co/papers/2504.01871,本论文首次提供了模型无关强化学习代理可以进行内部规划的机制性证据。研究集中于Sokoban这一经典规划基准，通过对DRC代理的分析，发现其利用学习到的概念表示来内部制定计划，从而预测行动对环境的长期影响并影响行动选择。研究方法包括探测与规划相关的概念、分析代理内部的计划形成过程，以及通过干预验证这些计划对行为的因果影响。此外，论文还表明，规划能力的出现与代理在额外测试计算下的表现提升相关，最终发现其学习到的规划算法与并行双向搜索有显著相似性。这些发现有助于深入理解代理的规划行为机制。,2
