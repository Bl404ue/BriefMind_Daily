标题,中文标题,发布日期,领域分类,研究机构,PDF链接,论文链接,AlphaXiv链接,简明摘要,点赞数
"When To Solve, When To Verify: Compute-Optimal Problem Solving and Generative Verification for LLM Reasoning",何时求解，何时验证：计算最优的问题解决与大语言模型推理的生成验证,01 Apr 2025,LLM,DeepMind,https://arxiv.org/pdf/2504.01005,https://www.arxiv.org/abs/2504.01005,https://www.alphaxiv.org/abs/2504.01005,本论文探讨了在大语言模型（LLM）推理中，如何在解决问题与验证答案之间进行计算优化。研究比较了自一致性（SC）和生成奖励模型（GenRM）在固定推理预算下的表现。结果表明，SC在大多数实际预算下更为计算高效，尤其在较低预算时，使用最多8倍的计算资源即可超越GenRM。论文还揭示了GenRM在计算资源消耗方面的局限性，提供了在测试时优化解决方案生成与验证的实用指导。这项研究为提高LLM的推理能力提供了重要见解。,38
m1: Unleash the Potential of Test-Time Scaling for Medical Reasoning with Large Language Models,m1：释放大语言模型在医学推理中的测试时间缩放潜力,01 Apr 2025,LLM,Amazon,https://arxiv.org/pdf/2504.00869,https://www.arxiv.org/abs/2504.00869,https://www.alphaxiv.org/abs/2504.00869,本文探讨了测试时间扩展（test-time scaling）在医学推理中的应用，提出了一种名为m1的方法，以提高大型语言模型（LLMs）在医学领域的推理能力。研究表明，通过增加“思考”令牌预算，m1能够显著提升模型在各种医学问答任务中的表现，尤其是10B参数的轻量级模型达到了新的最优水平。尽管32B模型的表现与70B规模的模型相当，但发现最佳的推理令牌预算约为4K，超出该范围可能导致性能下降。此外，研究指出，丰富的医学知识是实现性能提升的关键，而不仅仅是推理深度的增加。这些发现强调了医学推理与其他领域的根本差异。,32
WISE-TTT:Worldwide Information Segmentation Enhancement,WISE-TTT：全球信息分割增强,01 Apr 2025,Other,Other,https://arxiv.org/pdf/2504.00879,https://www.arxiv.org/abs/2504.00879,https://www.alphaxiv.org/abs/2504.00879,论文提出了一种新架构WISE-TTT，通过将测试时训练（TTT）机制与Transformer架构相结合，解决了视频多目标分割中的长期依赖问题。该方法通过压缩历史时间数据生成包含全球信息的隐藏状态，从而实现多阶段上下文聚合。实验结果表明，WISE-TTT在Davis2017长视频基准测试中提高了3.1%的准确率，验证了全球信息在分割性能中的重要性。此研究为下一代跟踪系统奠定了基础，展示了自适应上下文感知分割技术的新范式。,7
Inference-Time Scaling for Generalist Reward Modeling,通用奖励建模的推理时间扩展,03 Apr 2025,LLM,THU,https://arxiv.org/pdf/2504.02495,https://www.arxiv.org/abs/2504.02495,https://www.alphaxiv.org/abs/2504.02495,本论文探讨了如何提升通用奖励建模的推理时间可扩展性，以改善大型语言模型（LLMs）的强化学习效果。研究提出了一种新的学习方法——自我原则批评调优（SPCT），通过在线强化学习促进奖励生成，进而提高模型的灵活性和准确性。作者采用了点对点生成奖励建模（GRM）和元奖励建模（Meta RM）来优化计算资源的使用，并通过并行采样提升推理性能。实验证明，SPCT显著提升了GRM的质量和可扩展性，超越了现有方法，且在多个奖励建模基准上表现优异。该研究为通用奖励系统的进一步发展提供了新的思路。,1
Generative Evaluation of Complex Reasoning in Large Language Models,大型语言模型中的复杂推理生成评估,03 Apr 2025,LLM,"PKU, THU",https://arxiv.org/pdf/2504.02810,https://www.arxiv.org/abs/2504.02810,https://www.alphaxiv.org/abs/2504.02810,本论文提出了KUMO，一个针对大型语言模型（LLMs）推理能力的生成评估框架。KUMO结合了符号引擎，动态生成多轮推理任务，旨在评估模型的真实推理能力而非简单记忆。通过对23种先进LLMs在5000个任务上的评估，研究发现许多模型在简单推理任务上超过了大学生的表现，而在复杂推理挑战中也达到了大学水平。此外，KUMO任务的表现与新发布的真实世界推理基准高度相关，证明了其作为评估LLMs推理能力的有效性和持久性。,0
From Consumption to Collaboration: Measuring Interaction Patterns to Augment Human Cognition in Open-Ended Tasks,从消费到协作：测量互动模式以增强开放式任务中的人类认知,03 Apr 2025,LLM,Other,https://arxiv.org/pdf/2504.02780,https://www.arxiv.org/abs/2504.02780,https://www.alphaxiv.org/abs/2504.02780,本论文探讨了生成性人工智能（尤其是大型语言模型）对人类认知过程的影响，特别是在开放性任务中的应用。作者提出了一种框架，通过分析人类与大型语言模型的互动模式，评估其在促进或削弱人类思维中的作用。研究重点在于理解和测量认知活动的探索与利用，以及参与的建设性与有害性。这一框架为设计能够增强人类认知能力的AI系统提供了理论基础和实践指导，旨在避免对生成答案的被动消费，从而促进更深层次的思考和解决问题的能力。,0
Affordable AI Assistants with Knowledge Graph of Thoughts,具有思维知识图的经济型AI助手,03 Apr 2025,Agent,Other,https://arxiv.org/pdf/2504.02670,https://www.arxiv.org/abs/2504.02670,https://www.alphaxiv.org/abs/2504.02670,本文提出了知识图谱思维（KGoT），一种创新的AI助手架构，旨在降低大语言模型（LLM）驱动的代理系统的运营成本并提高其任务成功率。KGoT通过动态构建知识图谱，提取并结构化任务相关知识，结合外部工具（如数学求解器和网络爬虫），使得低成本模型能够有效解决复杂任务。研究表明，KGoT在GAIA基准测试中比Hugging Face Agents（使用GPT-4o mini）提高了29%的任务成功率，同时成本降低超过36倍。这一架构为开发经济实惠且高效的AI助手提供了可扩展的解决方案。,0
Multi-Mission Tool Bench: Assessing the Robustness of LLM based Agents through Related and Dynamic Missions,多任务工具基准：通过相关和动态任务评估基于LLM的智能体的鲁棒性,03 Apr 2025,Agent,Tencent,https://arxiv.org/pdf/2504.02623,https://www.arxiv.org/abs/2504.02623,https://www.alphaxiv.org/abs/2504.02623,本论文提出了“多任务工具基准”（Multi-Mission Tool Bench），旨在评估基于大型语言模型（LLM）的智能体在复杂动态任务中的鲁棒性。现有基准主要集中于单一任务，无法反映现实世界的复杂性。该基准设计了多个相互关联的任务，要求智能体能够动态适应变化的需求。通过构建一个多智能体数据生成框架，论文探索了所有可能的任务切换模式，并引入动态决策树评价方法，以评估智能体决策的准确性和效率。实验结果揭示了影响智能体鲁棒性的关键因素，为工具调用领域的未来研究提供了重要见解。,0
BOOST: Bootstrapping Strategy-Driven Reasoning Programs for Program-Guided Fact-Checking,BOOST: 基于引导策略的推理程序的引导生成用于程序指导的事实核查,03 Apr 2025,LLM,Other,https://arxiv.org/pdf/2504.02467,https://www.arxiv.org/abs/2504.02467,https://www.alphaxiv.org/abs/2504.02467,本文提出了BOOST，一个基于引导的框架，用于生成少量示例的推理程序，以支持复杂的事实核查。BOOST通过整合声明分解和信息收集策略，提供结构化指导，逐步优化推理程序的生成过程，避免了对人工示例的依赖。该方法实现了从零样本到少样本的无缝过渡，增强了推理的可解释性和有效性。实验结果表明，BOOST在复杂声明验证任务中优于现有的少样本基线，展示了其在自动化事实核查中的潜力。,0
LLMs as Deceptive Agents: How Role-Based Prompting Induces Semantic Ambiguity in Puzzle Tasks,大语言模型作为欺骗性智能体：基于角色的提示如何在难题任务中引发语义模糊,03 Apr 2025,Agent,Other,https://arxiv.org/pdf/2504.02254,https://www.arxiv.org/abs/2504.02254,https://www.alphaxiv.org/abs/2504.02254,本研究探讨了大型语言模型（LLMs）在生成谜题时如何利用语义模糊性进行欺骗性行为。通过比较零-shot提示与角色注入的对抗性提示，研究发现后者显著增加了谜题的复杂性和认知负担，从而降低了解题的公平性。利用HateBERT进行计算分析和人类主观评估，研究揭示了LLMs在自主决策中的新兴代理特性，并强调了在教育技术和娱乐领域安全部署自主语言系统的重要伦理考量。这些发现为理解LLMs的代理行为提供了重要见解，并为未来的研究奠定了基础。,0
A Survey of Scaling in Large Language Model Reasoning,大语言模型推理中的扩展调查,02 Apr 2025,LLM,Other,https://arxiv.org/pdf/2504.02181,https://www.arxiv.org/abs/2504.02181,https://www.alphaxiv.org/abs/2504.02181,本论文对大型语言模型（LLMs）推理能力的扩展进行了全面调查，探讨了不同的扩展策略如何影响推理性能。作者分析了输入大小、推理步骤、推理轮次和训练优化等多个维度的扩展，指出尽管数据和模型规模的增加通常能提升性能，但在推理任务中，简单的扩展可能会带来复杂性和挑战。通过对这些策略的深入分析，论文旨在为未来的AI系统发展提供指导，帮助提升LLMs在复杂推理任务中的表现。,0
Exploring LLM Reasoning Through Controlled Prompt Variations,通过控制提示变体探索大语言模型的推理,02 Apr 2025,LLM,Other,https://arxiv.org/pdf/2504.02111,https://www.arxiv.org/abs/2504.02111,https://www.alphaxiv.org/abs/2504.02111,本研究探讨了大型语言模型（LLMs）在数学问题解决任务中的推理稳健性，尤其是在面对不同类型的输入扰动时的表现。通过对GSM8K数据集的系统评估，研究发现引入无关上下文显著降低了模型的性能，表明区分重要与次要信息仍然是一个挑战。此外，模型的性能回归与推理任务的复杂性以及模型规模没有严格关联。某些扰动甚至意外激发了链式思维的推理行为。研究结果揭示了当前LLMs的关键脆弱性，并强调了提高其在现实应用中对噪声和误导性输入的鲁棒性的重要性。,0
Self-Resource Allocation in Multi-Agent LLM Systems,多智能体LLM系统中的自我资源分配,02 Apr 2025,Agent,Other,https://arxiv.org/pdf/2504.02051,https://www.arxiv.org/abs/2504.02051,https://www.alphaxiv.org/abs/2504.02051,本论文探讨了大型语言模型（LLMs）在多智能体系统中的自我资源分配能力，重点研究了任务分配和协调的有效性。通过实验，作者比较了两种方法——指挥者和规划者，发现规划者在处理并发行动时表现更佳，能够提高效率和资源利用率。此外，提供关于工作者能力的明确信息能进一步优化规划者的任务分配策略。研究结果表明，LLMs在资源分配任务中具有高效性和准确性，为多智能体系统的优化提供了新的视角。,0
On Vanishing Variance in Transformer Length Generalization,关于变压器长度泛化中的消失方差,03 Apr 2025,LLM,Other,https://arxiv.org/pdf/2504.02827,https://www.arxiv.org/abs/2504.02827,https://www.alphaxiv.org/abs/2504.02827,本论文探讨了Transformer模型在长度泛化中的“消失方差”问题。研究表明，随着输入序列长度的增加，Transformer的多头注意力模块输出的方差会降低，导致模型在处理长序列时的准确性下降。作者首次提出在注意力输出后应用层归一化可以显著改善模型的长度泛化能力，部分缓解由消失方差引起的分布转移。该研究为理解和改进Transformer在不同序列长度下的鲁棒性提供了新的视角，并鼓励未来在网络架构设计中考虑这一问题。,0
Envisioning Beyond the Pixels: Benchmarking Reasoning-Informed Visual Editing,超越像素的构想：基于推理的视觉编辑基准测试,03 Apr 2025,Multimodal LLM,Shanghai AI Lab,https://arxiv.org/pdf/2504.02826,https://www.arxiv.org/abs/2504.02826,https://www.alphaxiv.org/abs/2504.02826,本论文介绍了RISEBench，一个首个专门用于评估“推理驱动视觉编辑”（RISE）的基准测试。尽管大型多模态模型在视觉理解和生成方面取得了显著进展，但在复杂指令的执行、外观一致性保持和灵活输入格式支持方面仍存在挑战。RISEBench围绕时间、因果、空间和逻辑推理四种关键类型，设计了高质量测试案例，并提出了评估框架。实验表明，尽管最先进的模型如GPT-4o-Native在性能上优于其他模型，但在逻辑推理任务上仍显不足。该基准旨在为推理感知的视觉编辑提供基础性见解，并推动未来相关研究的发展。,0
Systematic Evaluation of Large Vision-Language Models for Surgical Artificial Intelligence,大型视觉-语言模型在外科人工智能中的系统评估,03 Apr 2025,Multimodal LLM,DeepMind,https://arxiv.org/pdf/2504.02799,https://www.arxiv.org/abs/2504.02799,https://www.alphaxiv.org/abs/2504.02799,本论文系统评估了11种大型视觉语言模型（VLMs）在外科人工智能中的应用，涵盖17项关键的视觉理解任务，如解剖识别和技能评估。研究表明，VLMs在多种外科情境中表现出良好的泛化能力，且在某些情况下超越了传统监督模型。通过在测试中引入示例，模型性能提升显著。然而，涉及空间和时间推理的任务仍然具有挑战性。这项研究为VLMs在复杂临床场景中的潜力提供了重要见解，预示着它们在医学领域的广泛应用前景。,0
How Deep Do Large Language Models Internalize Scientific Literature and Citation Practices?,大型语言模型在多大程度上内化科学文献和引用实践？,03 Apr 2025,LLM,Other,https://arxiv.org/pdf/2504.02767,https://www.arxiv.org/abs/2504.02767,https://www.alphaxiv.org/abs/2504.02767,"本研究探讨了大型语言模型（LLMs）在科学文献和引用实践中的作用。通过分析274,951个由GPT-4o生成的引用，发现LLMs倾向于偏爱高被引论文，并强化了“马太效应”，即更受欢迎的论文获得更多引用。研究表明，LLMs生成的引用在语义上与论文内容高度一致，但更倾向于选择较新、标题较短和作者较少的文献。这些发现揭示了LLMs如何可能改变科学引用模式，影响科学发现的进程，强调了理解其在研究中的角色的重要性。",0
SymDQN: Symbolic Knowledge and Reasoning in Neural Network-based Reinforcement Learning,SymDQN：基于神经网络的强化学习中的符号知识与推理,03 Apr 2025,Agent,Other,https://arxiv.org/pdf/2504.02654,https://www.arxiv.org/abs/2504.02654,https://www.alphaxiv.org/abs/2504.02654,本文提出了一种新的学习架构SymDQN，旨在通过结合符号知识和推理来增强基于深度神经网络的强化学习。SymDQN在现有的Dueling Deep Q-Networks（DuelDQN）架构基础上，集成了逻辑张量网络（LTNs）模块，以指导行动策略学习。通过在一个5x5的网格环境中进行实验，结果表明，SymDQN显著提高了学习性能和代理的行为精确性。这一模块化的方法展示了将神经网络与符号推理相结合的潜力，为提高人工智能的可解释性和可靠性提供了新思路。,0
Test-time Adaptation for Foundation Medical Segmentation Model without Parametric Updates,无参数更新的基础医学分割模型的测试时适应,02 Apr 2025,Other,Other,https://arxiv.org/pdf/2504.02008,https://www.arxiv.org/abs/2504.02008,https://www.alphaxiv.org/abs/2504.02008,本论文提出了一种无需参数更新的测试时适应方法，旨在提高基础医学分割模型MedSAM在特定病变上的表现。研究发现，直接优化图像嵌入可以实现与参数更新相似的效果，从而避免大模型中的灾难性遗忘，并显著降低计算复杂性。通过结合分布近似的条件随机场损失和熵最小化损失，实验结果显示该方法在三个数据集上的Dice系数提高了约3%，同时计算复杂性减少了超过7倍。这一研究为医学图像分割领域提供了高效且有效的解决方案。,0
Concept Lancet: Image Editing with Compositional Representation Transplant,Concept Lancet: 基于组合表示移植的图像编辑,03 Apr 2025,Diffusion Model,Other,https://arxiv.org/pdf/2504.02828,https://www.arxiv.org/abs/2504.02828,https://www.alphaxiv.org/abs/2504.02828,这篇论文提出了Concept Lancet (CoLan)，一个用于基于扩散模型的图像编辑的零-shot框架。CoLan通过在潜在空间中对源图像进行稀疏线性组合分解，准确估计图像中概念的存在，从而解决了编辑强度估计不当带来的视觉一致性问题。该方法根据不同的编辑任务（如替换、添加或移除）进行定制化的概念移植，显著提升了编辑效果和一致性。实验表明，CoLan在多个基线模型上达到了最先进的性能，为图像编辑提供了新思路。,0
Efficient Autoregressive Shape Generation via Octree-Based Adaptive Tokenization,基于八叉树的自适应形状生成的高效自回归方法,03 Apr 2025,Other,Other,https://arxiv.org/pdf/2504.02817,https://www.arxiv.org/abs/2504.02817,https://www.alphaxiv.org/abs/2504.02817,本文提出了一种名为Octree-based Adaptive Tokenization（OAT）的新框架，旨在提高3D形状生成的效率。与传统方法使用固定大小的潜在表示不同，OAT根据形状的复杂性动态调整潜在表示的维度。通过构建自适应的八叉树结构并使用查询变换器分配形状潜在向量，该方法在保持可比视觉质量的同时，将令牌数量减少了50%。实验表明，OAT能够生成更详细和多样化的3D内容，显著提升了生成模型的性能，解决了现有方法在形状表示上的不足。,0
Spline-based Transformers,基于样条的变换器,03 Apr 2025,Other,Other,https://arxiv.org/pdf/2504.02797,https://www.arxiv.org/abs/2504.02797,https://www.alphaxiv.org/abs/2504.02797,本论文提出了一种新的变换器模型——基于样条的变换器（Spline-based Transformers），该模型消除了对位置编码的需求。灵感来自计算机动画中的样条工作流程，作者通过将输入元素序列嵌入为潜在空间中的平滑轨迹，克服了传统位置编码的局限性，如序列长度外推能力差。基于样条的变换器允许用户通过直接操作潜在控制点来创建新的潜在轨迹和序列。实验表明，该方法在多种数据集上（包括合成2D和大规模真实世界图像、3D形状及动画）表现优于传统位置编码的模型，展示了其在学习元素和集合数据表示方面的潜力。,0
GPT-ImgEval: A Comprehensive Benchmark for Diagnosing GPT4o in Image Generation,GPT-ImgEval：用于诊断GPT4o在图像生成中的综合基准,03 Apr 2025,Multimodal LLM,"PKU, Shanghai AI Lab",https://arxiv.org/pdf/2504.02782,https://www.arxiv.org/abs/2504.02782,https://www.alphaxiv.org/abs/2504.02782,论文《GPT-ImgEval: A Comprehensive Benchmark for Diagnosing GPT4o in Image Generation》介绍了一个名为GPT-ImgEval的评估基准，用于系统性地诊断OpenAI的GPT-4o模型在图像生成和编辑方面的能力。研究涵盖了三个核心任务：文本到图像生成、基于指令的图像编辑和知识驱动的语义合成。结果显示，GPT-4o在生成质量、编辑能力和知识推理方面表现优异，超越了现有方法。此外，论文还探讨了GPT-4o的潜在架构，提出其可能结合了自回归和扩散模型的特征。这项工作为未来的研究提供了可靠的基准，有助于推动图像生成领域的创新。,0
Scene Splatter: Momentum 3D Scene Generation from Single Image with Video Diffusion Model,场景溅射：基于视频扩散模型的单幅图像动量3D场景生成,03 Apr 2025,Diffusion Model,"THU, Tencent",https://arxiv.org/pdf/2504.02764,https://www.arxiv.org/abs/2504.02764,https://www.alphaxiv.org/abs/2504.02764,本文提出了一种新颖的3D场景生成方法——Scene Splatter，利用视频扩散模型从单幅图像生成高保真和一致的3D场景。现有方法在生成过程中常遇到视频长度限制和场景不一致的问题，导致重建时出现伪影和失真。为了解决这些问题，本文引入了基于动量的策略，通过构建噪声样本来增强视频细节并保持场景一致性。此外，结合像素级动量的引入，能够更好地恢复未知区域。实验结果表明，该方法在高质量场景生成方面具有显著的优越性和广泛的适用性。,0
RBR4DNN: Requirements-based Testing of Neural Networks,RBR4DNN: 基于需求的神经网络测试,03 Apr 2025,Diffusion Model,Other,https://arxiv.org/pdf/2504.02737,https://www.arxiv.org/abs/2504.02737,https://www.alphaxiv.org/abs/2504.02737,本论文提出了一种基于需求的深度神经网络（DNN）测试方法，旨在提高关键系统的可靠性和安全性。研究者们利用结构化自然语言需求，通过文本条件的潜在扩散模型生成测试用例，并利用后条件定义测试 oracle 来评估 DNN 输出。实验结果表明，生成的测试套件在现实性、多样性和一致性方面表现良好，能够有效揭示潜在故障。这一方法为将 DNN 测试与需求分析结合提供了新的思路，推动了关键系统软件验证的发展。,0
Responsible Development of Offensive AI,负责任的进攻性人工智能发展,03 Apr 2025,Agent,Other,https://arxiv.org/pdf/2504.02701,https://www.arxiv.org/abs/2504.02701,https://www.alphaxiv.org/abs/2504.02701,这篇论文探讨了进攻性人工智能（AI）的负责任发展，旨在通过可持续发展目标（SDGs）和可解释性技术来指导研究优先级的确定。作者分析了两种进攻性AI形式：漏洞检测代理和AI驱动的恶意软件，强调在提升网络安全的同时，需平衡社会利益与风险。研究提出，开发这些工具必须考虑其对社会的潜在影响，特别是如何防止恶意行为者利用这些技术。通过评估社会收益与风险，论文为AI的负责任应用提供了重要的伦理框架和实用建议。,0
Improving User Experience with FAICO: Towards a Framework for AI Communication in Human-AI Co-Creativity,通过FAICO改善用户体验：构建人机共创中的AI沟通框架,03 Apr 2025,Other,Other,https://arxiv.org/pdf/2504.02526,https://www.arxiv.org/abs/2504.02526,https://www.alphaxiv.org/abs/2504.02526,本文提出了一种名为FAICO的框架，旨在改善人机共创中的AI沟通效果。通过对107篇相关文献的系统评审，FAICO识别了AI沟通的关键要素及其对用户体验的影响，并提供了设计指导。研究展示了如何将该框架转化为实用工具，包括设计卡片和配置工具，帮助设计师和用户根据不同需求定制AI沟通方式。该论文为人机共创和人机交互领域提供了新见解，强调有效的AI沟通在提升用户体验中的重要性。,0
Exploration-Driven Generative Interactive Environments,探索驱动的生成交互环境,03 Apr 2025,Agent,Other,https://arxiv.org/pdf/2504.02515,https://www.arxiv.org/abs/2504.02515,https://www.alphaxiv.org/abs/2504.02515,本论文提出了一种探索驱动的生成互动环境框架，旨在简化多环境世界模型的训练过程。传统方法依赖于昂贵的人类演示数据，而我们通过引入一种名为AutoExplore Agent的随机探索代理，利用环境模型的不确定性生成多样化的数据。这种方法使得模型能够快速适应新环境，并提高视频质量和可控性。此外，我们构建了一个名为RetroAct的大型数据集，涵盖974个虚拟环境，以支持高效的数据收集和训练。我们的研究为无缝扩展到新环境提供了新的解决方案。,0
A Memory-Augmented LLM-Driven Method for Autonomous Merging of 3D Printing Work Orders,一种基于记忆增强的大语言模型驱动的3D打印工单自主合并方法,03 Apr 2025,LLM,Other,https://arxiv.org/pdf/2504.02509,https://www.arxiv.org/abs/2504.02509,https://www.alphaxiv.org/abs/2504.02509,本文提出了一种基于大语言模型（LLM）和记忆增强学习策略的自主合并3D打印工作订单的方法，以应对日益增长的个性化生产需求。该方法通过将打印设备和订单特征转化为可由LLM读取的自然语言提示模板，开发了订单-设备匹配工具和合并干扰检查模块。通过自我记忆学习策略，系统能够不断积累决策经验，提高订单分配的准确性和可靠性，从而显著提升生产线的处理效率。这项研究展示了LLM在工业应用中的潜力，并有效减少了决策中的错误。,0
The Self-Learning Agent with a Progressive Neural Network Integrated Transformer,集成了渐进神经网络的自学习智能体,03 Apr 2025,Agent,Other,https://arxiv.org/pdf/2504.02489,https://www.arxiv.org/abs/2504.02489,https://www.alphaxiv.org/abs/2504.02489,本论文提出了一种自学习代理，结合了LLaMA 3.2模型与渐进神经网络（PNN），旨在实现跨领域的持续学习，特别是在对话AI和代码生成方面。该框架利用预训练的LLaMA模型，能够以极少的数据训练新任务，避免了传统方法中的灾难性遗忘。代理通过自动从维基百科收集数据，实现动态任务添加和微调，并采用元学习和低秩适应（LoRA）优化效率。实验表明，该系统在有限数据下展现出强大的任务适应性和知识保留能力，为向人工通用智能（AGI）迈进提供了新思路。,0
A Framework for Robust Cognitive Evaluation of LLMs,大语言模型的稳健认知评估框架,03 Apr 2025,LLM,Other,https://arxiv.org/pdf/2504.02789,https://www.arxiv.org/abs/2504.02789,https://www.alphaxiv.org/abs/2504.02789,本论文提出了一个名为COGNITIVE VAL的框架，旨在系统评估大型语言模型（LLMs）的认知能力。该框架通过自动生成多样化的提示和收集模型输出及其内部概率估计，增强了实验结果的稳健性。研究展示了COGNITIVE VAL在复制经典认知科学实验中的有效性，揭示了几种先进LLMs的认知特征。该框架的设计旨在促进认知科学社区的合作，为理解LLMs的认知机制提供了有力工具。,0
ERPO: Advancing Safety Alignment via Ex-Ante Reasoning Preference Optimization,ERPO：通过事前推理偏好优化推进安全对齐,03 Apr 2025,LLM,Other,https://arxiv.org/pdf/2504.02725,https://www.arxiv.org/abs/2504.02725,https://www.alphaxiv.org/abs/2504.02725,本论文提出了一种新的安全对齐框架——预先推理偏好优化（ERPO），旨在提升大型语言模型（LLMs）的安全性。ERPO通过链式思维增强模型的预先推理能力，并嵌入预定义的安全规则以支持安全判断。该方法分为三个阶段：首先，通过监督微调引入预先推理；其次，利用直接偏好优化提升模型的安全性和效率；最后，通过长度控制的迭代优化策略降低推理延迟。实验结果表明，ERPO显著提高了模型的安全性能，同时保持了响应效率，为应对潜在的有害内容提供了有效解决方案。,0
LLM for Complex Reasoning Task: An Exploratory Study in Fermi Problems,复杂推理任务的LLM：费米问题的探索性研究,03 Apr 2025,LLM,Other,https://arxiv.org/pdf/2504.02671,https://www.arxiv.org/abs/2504.02671,https://www.alphaxiv.org/abs/2504.02671,"本研究探讨了大型语言模型（LLMs）在解决费米问题（Fermi Problems, FPs）中的能力与局限性。FPs是一类复杂的数学推理任务，常因模糊性和现实世界的不切实际性而难以解决。研究评估了三种先进LLMs在公开FP数据集上的表现，结果显示它们的得分均低于0.5，表明这些任务的内在困难。通过将FPs分为标准和特定问题，研究发现LLMs在标准问题上的表现优于特定问题。这项研究为理解LLMs在复杂推理任务中的表现提供了重要见解，并揭示了进一步改进的方向。",0
LexPam: Legal Procedure Awareness-Guided Mathematical Reasoning,LexPam: 法律程序意识引导的数学推理,03 Apr 2025,LLM,Other,https://arxiv.org/pdf/2504.02590,https://www.arxiv.org/abs/2504.02590,https://www.alphaxiv.org/abs/2504.02590,本论文提出了LexPam，一个基于法律程序意识的强化学习算法，旨在提升大型语言模型（LLM）在法律数学推理方面的能力。研究中引入了首个中文法律数学推理数据集LexNum，涵盖经济赔偿、工伤赔偿和交通事故赔偿三种常见场景。通过对现有法律LLM和推理模型的性能测试，发现其在法律数学推理任务中的表现不尽如人意。LexPam通过增强法律背景下的推理过程，显著提高了模型的数学推理能力，为法律咨询的可信性提供了支持。,0
AnesBench: Multi-Dimensional Evaluation of LLM Reasoning in Anesthesiology,AnesBench：麻醉学中大语言模型推理的多维评估,03 Apr 2025,LLM,Other,https://arxiv.org/pdf/2504.02404,https://www.arxiv.org/abs/2504.02404,https://www.alphaxiv.org/abs/2504.02404,本论文提出了ANESBENCH，这是一个针对麻醉学领域的大型语言模型（LLM）推理能力的多维评估基准。研究系统地评估了LLM在麻醉学中的推理能力，分析了影响其表现的关键因素，包括模型特征、训练策略和推理技术。通过实验，作者探讨了事实检索、混合推理和复杂决策三种推理层次，并提供了相应的数据集和评估代码，以促进麻醉学相关的人工智能研究。该工作为提升医疗领域中LLM的应用提供了重要的参考和资源。,0
SPACE: SPike-Aware Consistency Enhancement for Test-Time Adaptation in Spiking Neural Networks,SPACE: 适应脉冲神经网络测试时的脉冲感知一致性增强,03 Apr 2025,Other,Other,https://arxiv.org/pdf/2504.02298,https://www.arxiv.org/abs/2504.02298,https://www.alphaxiv.org/abs/2504.02298,本文提出了SPACE（SPike-Aware Consistency Enhancement），这是首个专为脉冲神经网络（SNNs）设计的源无关单实例测试时适应方法。SNNs在应对数据分布变化时表现出高度敏感性，传统的测试时适应方法常常无法有效应对其独特的计算动态。SPACE利用SNNs固有的脉冲动态，通过增强单个测试样本的局部特征图一致性，实现在没有源数据的情况下进行稳健适应。实验结果表明，SPACE在多个数据集上超越了现有最先进的方法，展示了其在实际应用中的有效性和鲁棒性。,0
F-ViTA: Foundation Model Guided Visible to Thermal Translation,F-ViTA: 基于基础模型的可见光到热成像转换,03 Apr 2025,Diffusion Model,Other,https://arxiv.org/pdf/2504.02801,https://www.arxiv.org/abs/2504.02801,https://www.alphaxiv.org/abs/2504.02801,本文提出了一种新颖的方法F-ViTA，旨在改善从可见光图像到热成像的转换。传统方法通常依赖于生成对抗网络或扩散模型，面临数据稀缺和过拟合问题。F-ViTA利用基础模型中的知识，通过零-shot掩码和标签来指导扩散过程，从而更好地学习场景对象与其热特征之间的关系。实验结果表明，F-ViTA在多个公共数据集上超越了现有的最先进方法，并且在处理未知数据时表现出良好的泛化能力。此外，F-ViTA还支持用户通过文本提示生成特定类型的红外图像，拓展了现有研究的应用范围。,0
