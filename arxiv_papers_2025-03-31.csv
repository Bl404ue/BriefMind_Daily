标题,中文标题,发布日期,领域分类,研究机构,PDF链接,论文链接,AlphaXiv链接,简明摘要,点赞数
Video-R1: Reinforcing Video Reasoning in MLLMs,Video-R1：在多模态大语言模型中强化视频推理,27 Mar 2025,Multimodal LLM,Other,https://arxiv.org/pdf/2503.21776,https://www.arxiv.org/abs/2503.21776,https://www.alphaxiv.org/abs/2503.21776,论文《Video-R1: Reinforcing Video Reasoning in MLLMs》首次系统地探讨了在多模态大语言模型中通过强化学习（RL）提升视频推理能力的方法。研究提出了T-GRPO算法，以解决视频推理中的时间建模不足和高质量数据稀缺两个主要挑战。通过结合图像推理数据与构建两个新数据集，Video-R1在多个视频推理基准测试中取得显著提升，尤其在VSI-Bench上，Video-R1-7B的准确率达到35.8%，超越了商业模型GPT-4o。该研究为视频推理领域的进一步发展奠定了基础。,33
MemInsight: Autonomous Memory Augmentation for LLM Agents,MemInsight：用于LLM智能体的自主记忆增强,27 Mar 2025,LLM,Amazon,https://arxiv.org/pdf/2503.21760,https://www.arxiv.org/abs/2503.21760,https://www.alphaxiv.org/abs/2503.21760,本文提出了一种名为MemInsight的自主记忆增强方法，旨在提高大型语言模型（LLM）代理的记忆能力和信息检索效果。MemInsight通过自动生成语义和上下文信息的增强，帮助代理更有效地识别和利用历史交互数据，从而在对话推荐、问答和事件摘要等任务中提供更准确和个性化的响应。实验证明，MemInsight在提升推荐的说服力方面可提高14%，在回忆检索中超越基线模型34%。该方法展示了如何通过优化记忆管理来增强LLM代理的上下文表现和适应能力。,32
"Embodied-Reasoner: Synergizing Visual Search, Reasoning, and Action for Embodied Interactive Tasks",具身推理器：协同视觉搜索、推理和行动以实现具身交互任务,27 Mar 2025,Embodied AI,Alibaba,https://arxiv.org/pdf/2503.21696,https://www.arxiv.org/abs/2503.21696,https://www.alphaxiv.org/abs/2503.21696,本文提出了“Embodied-Reasoner”模型，旨在提升在复杂环境中进行互动搜索任务的能力。该模型通过结合视觉搜索、推理和行动，处理需要空间理解和时间推理的任务。研究中合成了9.3千条连贯的观察-思考-行动轨迹，包含64k张互动图像和90k种思维过程。通过模仿学习、自我探索和反思调优的三阶段训练流程，模型在多个评估中显著超越现有的视觉推理模型，尤其在复杂的长时间任务中表现出更少的重复搜索和逻辑不一致性，展示了其在真实环境中的优势。这为未来的互动智能体研究提供了新思路。,26
Test-Time Visual In-Context Tuning,测试时视觉上下文调优,27 Mar 2025,Other,Google,https://arxiv.org/pdf/2503.21777,https://www.arxiv.org/abs/2503.21777,https://www.alphaxiv.org/abs/2503.21777,本文提出了一种新的方法——测试时视觉上下文调优（VICT），旨在提升视觉上下文学习（VICL）模型在分布变化下的泛化能力。现有的VICL模型在面对未见过的新领域时表现不佳，尤其是在测试分布与训练分布不一致时。VICT通过利用单个测试样本动态调整模型，使其能够更好地适应新的测试分布。具体而言，VICT通过重构任务提示的输出，利用循环一致性损失进行自我监督调优。实验结果表明，VICT在六个视觉任务上显著提高了模型的泛化能力，为未见任务的实时适应提供了潜在的解决方案。,15
LLM-Gomoku: A Large Language Model-Based System for Strategic Gomoku with Self-Play and Reinforcement Learning,LLM-Gomoku：基于大语言模型的战略五子棋系统，结合自我对弈和强化学习,27 Mar 2025,LLM,Other,https://arxiv.org/pdf/2503.21683,https://www.arxiv.org/abs/2503.21683,https://www.alphaxiv.org/abs/2503.21683,该论文提出了一种基于大型语言模型（LLM）的Gomoku AI系统，旨在通过自我对弈和强化学习模拟人类棋手的学习过程。系统能够“读取棋盘”、理解游戏规则、选择策略和评估局势，从而做出理性决策。研究表明，该方法显著提高了走棋位置的选择，解决了生成非法位置的问题，并通过并行评估减少了处理时间。经过广泛的自我对弈训练，该模型在Gomoku游戏中的表现得到了显著提升，为将LLM应用于复杂策略游戏提供了新的思路。,13
ReaRAG: Knowledge-guided Reasoning Enhances Factuality of Large Reasoning Models with Iterative Retrieval Augmented Generation,ReaRAG：知识引导推理增强大推理模型的事实性，采用迭代检索增强生成,27 Mar 2025,LLM,THU,https://arxiv.org/pdf/2503.21729,https://www.arxiv.org/abs/2503.21729,https://www.alphaxiv.org/abs/2503.21729,论文提出了ReaRAG，一种通过知识引导的推理模型，旨在提升大型推理模型（LRMs）在多跳问答任务中的事实准确性。ReaRAG采用迭代检索增强生成的方法，构建知识引导的推理链，避免过度思考和错误传播。通过限制推理链的最大长度和使用思考-行动-观察的范式，ReaRAG能够在检索过程中反思并纠正推理路径，从而提高问答性能。实验结果表明，ReaRAG在多跳问答任务中优于现有基线，展示了其在增强LRMs事实性和推理能力方面的有效性。,12
A Measure Based Generalizable Approach to Understandability,基于度量的可理解性通用方法,27 Mar 2025,Agent,Other,https://arxiv.org/pdf/2503.21615,https://www.arxiv.org/abs/2503.21615,https://www.alphaxiv.org/abs/2503.21615,该论文提出了一种基于度量的通用方法，以改善智能代理与人类之间的沟通理解能力。现有的智能代理（如大型语言模型）在理解人类需求方面存在局限，主要依赖训练数据，无法细致区分个体用户的感知和期望。论文通过调查不同领域的理解能力度量，倡导建立更为一致和领域无关的理解性标准，以提高代理的可操控性和有效性。这一方法为未来研究提供了认知科学基础，旨在促进智能代理更好地适应人类用户的需求。,4
VBench-2.0: Advancing Video Generation Benchmark Suite for Intrinsic Faithfulness,VBench-2.0：推进视频生成基准套件以实现内在真实性,27 Mar 2025,Other,Shanghai AI Lab,https://arxiv.org/pdf/2503.21755,https://www.arxiv.org/abs/2503.21755,https://www.alphaxiv.org/abs/2503.21755,论文《VBench-2.0: Advancing Video Generation Benchmark Suite for Intrinsic Faithfulness》提出了一种新的视频生成基准工具VBench-2.0，旨在评估视频生成模型的内在真实性。与以往主要关注表面质量的基准不同，VBench-2.0扩展了评估框架，涵盖人类忠实度、可控性、创造力、物理真实性和常识推理等五个关键维度，细分为18个能力指标。通过引入全面的评估方法，VBench-2.0旨在推动视频生成模型在遵循真实世界原则方面的进步，为AI辅助影视制作和模拟世界建模等应用奠定基础。,3
Semantic Library Adaptation: LoRA Retrieval and Fusion for Open-Vocabulary Semantic Segmentation,语义库适应：用于开放词汇语义分割的LoRA检索与融合,27 Mar 2025,Multimodal LLM,Google,https://arxiv.org/pdf/2503.21780,https://www.arxiv.org/abs/2503.21780,https://www.alphaxiv.org/abs/2503.21780,本文提出了一种名为语义库适应（SemLA）的新框架，旨在解决开放词汇语义分割模型在训练和测试领域之间的适应性问题。SemLA通过动态合并基于LoRA的适配器，利用CLIP嵌入索引相关适配器，从而在测试时无需额外训练即可快速适应目标领域。这种方法不仅提高了模型的灵活性和可解释性，还保护了数据隐私，适合于敏感应用。实验结果表明，SemLA在多种设置下表现出优越的适应性和性能，确立了开放词汇语义分割领域的新标准。,3
Unveiling the Mist over 3D Vision-Language Understanding: Object-centric Evaluation with Chain-of-Analysis,揭示3D视觉-语言理解中的迷雾：基于对象的链式分析评估,28 Mar 2025,Multimodal LLM,"PKU, THU",https://arxiv.org/pdf/2503.22420,https://www.arxiv.org/abs/2503.22420,https://www.alphaxiv.org/abs/2503.22420,本文提出了BEACON 3D，一个新颖的3D视觉-语言（3D-VL）基准，旨在解决现有评估方法的不足。研究指出，当前3D-VL基准存在测试数据质量差、评估指标过于简单、以及对任务间关联性忽视等问题，导致对模型能力的评估不够准确。BEACON 3D采用了高质量的测试数据和对象中心的评估框架，通过链式分析方法提升了对模型性能的理解。实验结果显示，现有模型在问答任务中表现不佳，且大语言模型的引入未能改善基础的定位能力。这项研究为3D-VL领域的进一步发展提供了重要的见解和指导。,0
DeepSound-V1: Start to Think Step-by-Step in the Audio Generation from Videos,DeepSound-V1：开始在视频生成音频中逐步思考,28 Mar 2025,Multimodal LLM,Other,https://arxiv.org/pdf/2503.22208,https://www.arxiv.org/abs/2503.22208,https://www.alphaxiv.org/abs/2503.22208,论文《DeepSound-V1》提出了一种新颖的框架，通过多模态大语言模型（MLLM）实现从视频生成音频的逐步推理，旨在解决当前视频与生成音频之间的对齐问题。由于缺乏足够的标注，现有方法在语义和时间对齐上表现不佳。该框架利用内部推理链，避免了额外标注的需求，并构建了相应的数据集以促进学习。实验结果表明，该方法在减少音频生成中的错位问题方面表现优异，相较于多种先进模型显著提高了生成质量，展现出更好的性能指标。,0
Enhance Generation Quality of Flow Matching V2A Model via Multi-Step CoT-Like Guidance and Combined Preference Optimization,通过多步骤类链式思维指导和组合偏好优化提升Flow Matching V2A模型的生成质量,28 Mar 2025,Multimodal LLM,Other,https://arxiv.org/pdf/2503.22200,https://www.arxiv.org/abs/2503.22200,https://www.alphaxiv.org/abs/2503.22200,本论文提出了一种多阶段的生成框架，名为Chain-of-Perform (CoP)，旨在提高视频引导音频生成模型Flow Matching V2A的音频生成质量。通过结合链式思维指导和偏好优化，CoP框架实现了视觉与音频之间的更精确的语义和时间对齐。研究采用了基于变换器的网络架构，实施了分步指导的训练过程，并构建了多模态数据集，支持专业音频（如钢琴音效）的生成。实验结果表明，CoP在多个数据集上的表现优于现有的最先进模型，显著提升了音频生成的质量。,0
REMAC: Self-Reflective and Self-Evolving Multi-Agent Collaboration for Long-Horizon Robot Manipulation,REMAC：用于长时间机器人操作的自我反思与自我演化多智能体协作,28 Mar 2025,Embodied AI,Other,https://arxiv.org/pdf/2503.22122,https://www.arxiv.org/abs/2503.22122,https://www.alphaxiv.org/abs/2503.22122,本文提出了一种自我反思和自我进化的多智能体协作框架REMAC，旨在提高机器人在动态环境中执行长时间任务的适应性和效率。REMAC通过自我反思模块和自我进化模块，允许机器人在任务执行过程中不断评估和调整计划。该框架无需复杂的任务提示，能够有效处理多阶段任务，同时支持多机器人协同工作。实验结果表明，REMAC在成功率和执行效率上分别比单机器人基线提高了40%和52.7%，显示出其在机器人计划中的显著优势。,0
CoT-VLA: Visual Chain-of-Thought Reasoning for Vision-Language-Action Models,CoT-VLA：视觉链式思维推理用于视觉-语言-行动模型,27 Mar 2025,Embodied AI,Other,https://arxiv.org/pdf/2503.22020,https://www.arxiv.org/abs/2503.22020,https://www.alphaxiv.org/abs/2503.22020,本文提出了一种新方法CoT-VLA，将视觉链式思维（CoT）推理融入视觉-语言-动作模型（VLA），以提高复杂操作任务中的推理能力。与传统VLA模型直接映射输入和输出不同，CoT-VLA首先生成中间目标图像，然后基于该图像生成行动序列。这一方法不仅能利用丰富的无标注视频数据，还在真实世界操作任务中提升了17%的性能，且在仿真基准测试中提升了6%。该研究为机器人学习提供了一种新的思路，增强了模型的视觉推理能力。,0
Data-Agnostic Robotic Long-Horizon Manipulation with Vision-Language-Guided Closed-Loop Feedback,基于视觉-语言引导的闭环反馈的数据无关机器人长时间操作,27 Mar 2025,Embodied AI,Other,https://arxiv.org/pdf/2503.21969,https://www.arxiv.org/abs/2503.21969,https://www.alphaxiv.org/abs/2503.21969,本文提出了DAHLIA，一个数据无关的框架，用于语言指导的长时间机器人操作，旨在克服现有方法在任务执行中的局限性。DAHLIA结合了大型语言模型（LLMs）进行实时任务规划和执行，通过双通道架构实现任务分解和可执行计划生成。该框架引入闭环反馈机制，增强了任务恢复能力，并通过时间抽象和思维链推理提升了决策过程的可追溯性和效率。实验表明，DAHLIA在多样化的长时间任务中表现出色，展示了良好的泛化能力，减少了对大量专家数据的依赖。,0
EgoToM: Benchmarking Theory of Mind Reasoning from Egocentric Videos,EgoToM：基于自我中心视频的心智理论推理基准测试,28 Mar 2025,Multimodal LLM,Meta,https://arxiv.org/pdf/2503.22152,https://www.arxiv.org/abs/2503.22152,https://www.alphaxiv.org/abs/2503.22152,本文介绍了EgoToM，一个新的视频问答基准，旨在评估从自我中心视频中推断他人心理状态（即理论心智）的能力。通过使用因果理论心智模型，研究者为Ego4D数据集生成了多项选择题，测试了人类和先进的多模态大语言模型（MLLMs）在推测摄像头佩戴者的目标、信念和未来行动方面的表现。结果显示，尽管MLLMs在推断目标时接近人类水平，但在信念和未来行动的推断上仍显不足。这项研究为未来设计具备用户内心状态理解能力的自我中心数字助手提供了重要的参考。,0
Collab: Controlled Decoding using Mixture of Agents for LLM Alignment,Collab：使用智能体混合进行受控解码以实现大语言模型对齐,27 Mar 2025,LLM,Other,https://arxiv.org/pdf/2503.21720,https://www.arxiv.org/abs/2503.21720,https://www.alphaxiv.org/abs/2503.21720,该论文提出了一种名为Collab的新方法，通过混合代理的解码策略来增强大型语言模型（LLM）的对齐能力。与传统的单代理解码方法相比，Collab在推理时动态选择最适合的模型，从而更好地适应多样化的任务需求。该方法利用现有的对齐LLM策略，通过令牌级别的选择机制实现高效的协作与对齐。实验结果显示，Collab在多个任务和偏好上显著超越了现有的最先进解码策略，平均奖励提高了1.56倍，GPT-4的胜平率提升了71.89%。这一创新为安全和可靠的LLM部署提供了新的思路。,0
DSO: Aligning 3D Generators with Simulation Feedback for Physical Soundness,DSO：通过仿真反馈对齐3D生成器以确保物理合理性,28 Mar 2025,Other,Other,https://arxiv.org/pdf/2503.22677,https://www.arxiv.org/abs/2503.22677,https://www.alphaxiv.org/abs/2503.22677,本论文提出了一种新的方法——直接仿真优化（DSO），旨在提高3D生成模型的物理稳定性。传统的3D生成模型通常专注于视觉效果，忽视了物体在重力下的自我支撑能力。DSO通过利用非可微分的物理仿真反馈来优化3D生成器，显著提高了生成稳定物体的概率，而无需在测试时进行复杂的优化。研究展示了DSO在无需真实3D对象训练的情况下，仍能有效提升生成器性能，且生成过程快速高效。这一方法为3D打印和仿真等应用提供了可靠的解决方案。,0
Zero4D: Training-Free 4D Video Generation From Single Video Using Off-the-Shelf Video Diffusion Model,Zero4D：基于现成视频扩散模型的单视频无训练4D视频生成,28 Mar 2025,Diffusion Model,Other,https://arxiv.org/pdf/2503.22622,https://www.arxiv.org/abs/2503.22622,https://www.alphaxiv.org/abs/2503.22622,论文提出了一种名为Zero4D的训练免算法，用于从单一的单目视频生成多视角同步的4D视频。该方法利用现成的视频扩散模型，首先通过深度估计技术合成关键帧，确保生成帧在空间和时间上的一致性。接着，通过插值生成其余帧，构建完整且时间一致的采样网格。Zero4D的创新之处在于无需额外训练，即可有效生成复杂的多视角视频，解决了传统4D生成方法在数据稀缺和计算成本高昂方面的挑战，为动态3D内容创作提供了实用的解决方案。,0
Scenario Dreamer: Vectorized Latent Diffusion for Generating Driving Simulation Environments,Scenario Dreamer：用于生成驾驶模拟环境的向量化潜在扩散,28 Mar 2025,Diffusion Model,Other,https://arxiv.org/pdf/2503.22496,https://www.arxiv.org/abs/2503.22496,https://www.alphaxiv.org/abs/2503.22496,论文《Scenario Dreamer》提出了一种全新的生成模拟器，旨在为自主驾驶规划生成驾驶环境。与现有方法不同，Scenario Dreamer采用了一种矢量化的潜在扩散模型，直接在抽象的场景元素上进行生成，避免了传统光栅化图像所带来的计算冗余。该模拟器不仅生成初始交通场景，还通过自回归Transformer模拟代理行为，提升了场景的多样性和真实性。实验表明，Scenario Dreamer在生成质量、效率和对强化学习代理的挑战性方面均优于现有生成模拟器，具备更高的实用价值。,0
Grasping a Handful: Sequential Multi-Object Dexterous Grasp Generation,抓取一把：顺序多物体灵巧抓取生成,28 Mar 2025,Embodied AI,Other,https://arxiv.org/pdf/2503.22370,https://www.arxiv.org/abs/2503.22370,https://www.alphaxiv.org/abs/2503.22370,本文介绍了一种新颖的顺序多物体抓取算法SeqGrasp，该算法能够有效地为多种物体生成稳定的抓取姿势。通过构建大规模的SeqDataset数据集，包含870K个抓取实例，研究者训练了条件顺序抓取扩散模型SeqDiffuser。实验结果表明，与现有的同时多物体抓取方法MultiGrasp相比，SeqGrasp和SeqDiffuser在抓取成功率上提高了8.71%-43.33%，且SeqDiffuser的抓取生成速度快约1000倍。该研究为机器人顺序抓取任务提供了有效的解决方案，并展示了其在模拟和实际机器人上的有效性。,0
Harmonizing Visual Representations for Unified Multimodal Understanding and Generation,统一多模态理解与生成的视觉表示协调,27 Mar 2025,Multimodal LLM,Shanghai AI Lab,https://arxiv.org/pdf/2503.21979,https://www.arxiv.org/abs/2503.21979,https://www.alphaxiv.org/abs/2503.21979,本论文提出了一种名为Harmon的统一自回归框架，旨在同时提升视觉理解和生成的能力。研究指出，现有方法在视觉表示上存在固有的异质性，难以兼顾理解和生成的需求。通过借鉴掩蔽图像建模（MIM）技术，Harmon利用共享的自回归编码器，实现了对视觉数据的丰富语义表示。经过三阶段训练，Harmon在多个图像生成基准测试中达到了最先进的结果，同时在理解任务上与专用语义编码器的表现相当。这一研究为多模态智能的发展提供了新的思路和方法。,0
Scaling Laws of Scientific Discovery with AI and Robot Scientists,人工智能与机器人科学家的科学发现规模法则,28 Mar 2025,Embodied AI,Other,https://arxiv.org/pdf/2503.22444,https://www.arxiv.org/abs/2503.22444,https://www.alphaxiv.org/abs/2503.22444,本论文提出了一种名为自主通用科学家（AGS）的系统，旨在通过结合人工智能和机器人技术，革新科学研究的各个阶段。AGS能够自动化从假设形成到实验执行的全过程，显著提高研究效率，减少对专门知识的依赖，并增强可重复性。作者认为，随着这些系统的普及和进步，科学发现将遵循新的扩展规律，推动创新和跨学科合作，最终改变科学研究的模式。论文为AGS框架提供了分类，描绘了未来科学研究的潜在演变。,0
Sell It Before You Make It: Revolutionizing E-Commerce with Personalized AI-Generated Items,在制作之前销售：通过个性化AI生成商品革新电子商务,28 Mar 2025,Other,Alibaba,https://arxiv.org/pdf/2503.22182,https://www.arxiv.org/abs/2503.22182,https://www.alphaxiv.org/abs/2503.22182,本论文提出了一种创新的电子商务模式，利用AI生成的个性化商品（AIGI）来优化产品设计和上市流程。通过在阿里巴巴部署的系统，商家可以基于文本描述生成高质量的商品图像，先进行市场销售，再决定是否生产，大幅减少了对实体原型的依赖，从而加快了上市时间。研究中还提出了一种个性化的用户偏好对齐框架（PerFusion），有效捕捉用户对多种候选图像的偏好。实验结果表明，AI生成的商品在点击率和转化率上均优于人工设计，展示了这一模式在电子商务中的变革潜力。,0
UI-R1: Enhancing Action Prediction of GUI Agents by Reinforcement Learning,UI-R1：通过强化学习增强GUI智能体的动作预测,27 Mar 2025,Multimodal LLM,Other,https://arxiv.org/pdf/2503.21620,https://www.arxiv.org/abs/2503.21620,https://www.alphaxiv.org/abs/_2503.21620,论文《UI-R1: Enhancing Action Prediction of GUI Agents by Reinforcement Learning》探讨了如何通过基于规则的强化学习（RL）来提升多模态大型语言模型（MLLM）在图形用户界面（GUI）动作预测任务中的推理能力。研究团队构建了一个高质量的小型数据集，并引入了统一的规则基础奖励机制，采用政策优化算法进行模型训练。实验结果表明，UI-R1-3B模型在多个任务上显著提高了准确性，尤其在内域和外域基准测试中表现出色。这一工作展示了基于规则的RL在GUI理解和控制中的潜力，为未来相关研究奠定了基础。,0
Unicorn: Text-Only Data Synthesis for Vision Language Model Training,Unicorn: 基于文本的数据合成用于视觉语言模型训练,28 Mar 2025,Multimodal LLM,Other,https://arxiv.org/pdf/2503.22655,https://www.arxiv.org/abs/2503.22655,https://www.alphaxiv.org/abs/2503.22655,论文《Unicorn: Text-Only Data Synthesis for Vision Language Model Training》提出了一种新颖的三阶段框架，用于仅通过文本合成高质量的多模态训练数据，以支持视觉语言模型（VLMs）的训练。该框架生成了两个数据集：Unicorn-1.2M和Unicorn-471K-Instruction，分别用于预训练和指令调优。通过利用大语言模型扩展文本描述并将其转换为视觉表示，Unicorn消除了对真实图像的依赖，从而降低了成本和存储需求，同时保持了数据的多样性和质量。这一方法为VLMs的训练提供了一个高效、可扩展的解决方案。,0
Challenges and Paths Towards AI for Software Engineering,软件工程中的人工智能挑战与路径,28 Mar 2025,Other,Other,https://arxiv.org/pdf/2503.22625,https://www.arxiv.org/abs/2503.22625,https://www.alphaxiv.org/abs/2503.22625,本文探讨了人工智能在软件工程中的应用进展及其面临的挑战。尽管生成式AI取得了显著成功，但要实现高水平的自动化，仍需解决多个关键瓶颈。论文首先提供了软件工程中AI应用任务的结构化分类，涵盖了代码生成、测试、维护等方面。其次，分析了当前方法的局限性，最后提出了未来研究方向，旨在推动这一快速发展的领域，帮助人类开发者专注于更重要的决策。,0
Audio-Plane: Audio Factorization Plane Gaussian Splatting for Real-Time Talking Head Synthesis,Audio-Plane: 基于音频因子平面的高斯喷溅实时合成说话人头部,28 Mar 2025,Other,Other,https://arxiv.org/pdf/2503.22605,https://www.arxiv.org/abs/2503.22605,https://www.alphaxiv.org/abs/2503.22605,本文提出了一种新颖的音频因子平面（Audio-Plane）基于高斯点云（Gaussian Splatting）的方法，用于实时合成逼真的动态人头视频。通过将4D体积表示分解为与音频无关的空间平面和与音频相关的平面，作者克服了密集4D网格存储的高成本和可扩展性问题。这种方法不仅提高了音频驱动的嘴部动态建模精度，还实现了高质量的音频与嘴唇同步。实验结果表明，该方法在生成速度和视觉效果之间达到了良好的平衡，为计算机图形学和多媒体领域的研究提供了新的思路。,0
Generative Latent Neural PDE Solver using Flow Matching,基于流匹配的生成潜在神经偏微分方程求解器,28 Mar 2025,Diffusion Model,Other,https://arxiv.org/pdf/2503.22600,https://www.arxiv.org/abs/2503.22600,https://www.alphaxiv.org/abs/2503.22600,本文提出了一种基于流匹配的生成潜在神经偏微分方程（PDE）求解器，旨在提高时间依赖性PDE的预测精度和稳定性。通过将PDE状态嵌入低维潜在空间，显著降低了计算成本。该框架利用自编码器将不同类型的网格映射到统一的结构化潜在网格上，从而捕捉复杂几何形状。研究表明，所提模型在准确性和长期稳定性方面优于多种确定性基线，展示了扩散模型在数据驱动PDE学习中的潜力。,0
KEVS: Enhancing Segmentation of Visceral Adipose Tissue in Pre-Cystectomy CT with Gaussian Kernel Density Estimation,KEVS：利用高斯核密度估计增强术前膀胱切除CT中内脏脂肪组织的分割,28 Mar 2025,Other,Other,https://arxiv.org/pdf/2503.22592,https://www.arxiv.org/abs/2503.22592,https://www.alphaxiv.org/abs/2503.22592,本文介绍了一种名为KEVS的新方法，用于在术前CT图像中自动化分割内脏脂肪组织（VAT），旨在提升膀胱切除术患者的术后预后评估。KEVS结合了深度学习语义分割模型与高斯核密度估计分析，能够在没有真实VAT掩模的情况下进行训练，克服了传统方法中的观察者间变异性和阈值选择的主观性。通过在20个CT扫描数据集上的验证，KEVS在VAT分割精度上比现有技术提高了4.80%至6.02%。这一研究为术前CT图像中VAT的准确评估提供了有效工具，可能改善患者的围手术期管理。,0
Comparing Methods for Bias Mitigation in Graph Neural Networks,比较图神经网络中的偏见缓解方法,28 Mar 2025,Other,Other,https://arxiv.org/pdf/2503.22569,https://www.arxiv.org/abs/2503.22569,https://www.alphaxiv.org/abs/2503.22569,本文探讨了图神经网络（GNNs）在生成人工智能（GenAI）系统数据准备中的重要性，特别是针对数据偏见的缓解方法。通过对德国信用数据集的实验分析，比较了数据稀疏化、特征修改和合成数据增强三种偏见缓解策略。研究表明，尽管所有方法均能改善公平性指标，但采用分层抽样和GraphSAGE进行合成数据增强的效果尤为显著，能够在提升模型表现的同时平衡人口代表性。这一研究为构建更公平的AI系统提供了实际见解。,0
QuestBench: Can LLMs ask the right question to acquire information in reasoning tasks?,QuestBench：大语言模型能否提出正确的问题以获取推理任务中的信息？,28 Mar 2025,LLM,"DeepMind, Google",https://arxiv.org/pdf/2503.22674,https://www.arxiv.org/abs/2503.22674,https://www.alphaxiv.org/abs/2503.22674,本论文提出了QuestBench，一个针对大型语言模型（LLMs）在推理任务中获取缺失信息能力的评估框架。研究将信息获取问题形式化为约束满足问题（CSP），特别关注在推理任务中缺失的变量分配。QuestBench包含多种任务，如逻辑推理、规划问题和数学问题，要求模型从选项中选择正确的澄清问题。尽管当前最先进的模型在某些任务上表现良好，但在逻辑推理和规划问题上准确率仅为40-50%。研究表明，解决明确推理问题的能力不足以保证在缺失信息情况下的成功，强调了对模型信息获取能力的深入研究的必要性。,0
ActionStudio: A Lightweight Framework for Data and Training of Action Models,ActionStudio：一个轻量级的行动模型数据与训练框架,28 Mar 2025,Agent,Other,https://arxiv.org/pdf/2503.22673,https://www.arxiv.org/abs/2503.22673,https://www.alphaxiv.org/abs/2503.22673,本文介绍了ActionStudio，一个轻量级且可扩展的数据和训练框架，旨在支持大型行动模型的开发。ActionStudio解决了现有基础设施在处理多样化代理数据和训练大型模型时的不足，提供了统一的轨迹格式和多种训练方法（如LoRA和分布式训练）。框架内置强大的数据预处理和验证工具，并开源了相关代码和数据集，以促进社区研究。通过在公共和行业基准上的验证，ActionStudio展示了其在实际应用中的有效性和可扩展性，为自主代理系统的研究和开发提供了重要支持。,0
On the Mistaken Assumption of Interchangeable Deep Reinforcement Learning Implementations,关于可互换深度强化学习实现的错误假设,28 Mar 2025,Agent,Other,https://arxiv.org/pdf/2503.22575,https://www.arxiv.org/abs/2503.22575,https://www.alphaxiv.org/abs/2503.22575,这篇论文探讨了深度强化学习（DRL）算法实现之间的可互换性假设，指出这一假设存在误区。通过差异测试，研究发现不同实现之间存在显著不一致性，这直接影响了性能和先前研究的结论。例如，在五个PPO实现中，有三种在50%的试验中表现出超人类水平，而其他两种的表现则低于15%。作者强调，代码级的不一致性是导致这些差异的主要原因，并呼吁DRL研究者进行可重复性研究以及采用差异测试方法，以提高实现的可靠性和研究的准确性。,0
WorkTeam: Constructing Workflows from Natural Language with Multi-Agents,WorkTeam：利用多智能体从自然语言构建工作流,28 Mar 2025,Agent,PKU,https://arxiv.org/pdf/2503.22473,https://www.arxiv.org/abs/2503.22473,https://www.alphaxiv.org/abs/2503.22473,"本文提出了WorkTeam，一个多代理自然语言转工作流（NL2Workflow）框架，旨在提高复杂任务的工作流构建效率。传统的工作流构建方法需要专业知识，且现有的单一代理方法在处理复杂指令时表现不佳。WorkTeam通过引入三个不同角色的代理（监督者、协调者和填充者）协作完成任务，显著提升了工作流的成功率。此外，论文还推出了HW-NL2Workflow数据集，包含3,695个真实业务样本，为相关研究提供了基础。该框架为企业提供了一种新的、有效的NL2Workflow服务解决方案。",0
Evaluating LLM-based Agents for Multi-Turn Conversations: A Survey,评估基于大语言模型的智能体在多轮对话中的表现：一项调查,28 Mar 2025,LLM,Microsoft,https://arxiv.org/pdf/2503.22458,https://www.arxiv.org/abs/2503.22458,https://www.alphaxiv.org/abs/2503.22458,本论文对基于大语言模型（LLM）的多轮对话代理的评估方法进行了系统性的综述。研究采用PRISMA框架，分析了近250篇相关学术文献，建立了评估内容和方法的双重分类体系。第一部分识别了多轮对话代理的关键组成部分及其评估维度，如任务完成度、响应质量和用户体验等。第二部分则分类了评估方法，包括人工标注、自动化指标和混合策略等。论文总结了现有研究的局限性，并提出未来改进方向，如实时评估管道和动态互动的评估指标，为研究者和从业者提供了全面的指导。,0
CPPO: Accelerating the Training of Group Relative Policy Optimization-Based Reasoning Models,CPPO：加速基于群体相对策略优化的推理模型训练,28 Mar 2025,Agent,Other,https://arxiv.org/pdf/2503.22342,https://www.arxiv.org/abs/2503.22342,https://www.alphaxiv.org/abs/2503.22342,本文提出了完成修剪策略优化（CPPO），旨在加速基于群体相对策略优化（GRPO）的推理模型训练。GRPO虽然有效，但因需为每个问题采样多个完成而导致高昂的训练成本。CPPO通过修剪低绝对优势的完成，显著减少了用于梯度计算的完成数量，从而加快训练速度。此外，论文还引入了动态完成分配策略，以提高GPU利用率。实验结果显示，CPPO在GSM8K和Math数据集上分别实现了高达8.32倍和3.51倍的加速，同时保持或提升了模型准确性。,0
Agent-Centric Personalized Multiple Clustering with Multi-Modal LLMs,基于多模态大语言模型的智能体中心个性化多重聚类,28 Mar 2025,Multimodal LLM,ByteDance,https://arxiv.org/pdf/2503.22241,https://www.arxiv.org/abs/2503.22241,https://www.alphaxiv.org/abs/2503.22241,本文提出了一种以代理为中心的个性化多重聚类框架，利用多模态大语言模型（MLLMs）来生成基于用户特定偏好的多样化数据分区。与传统方法依赖于固定特征或CLIP嵌入不同，本文的方法通过构建用户兴趣偏向的关系图，优化了聚类过程，提升了对用户需求的适应性。实验结果显示，该框架在Card Order和Card Suits基准上取得了显著的性能提升，NMI得分分别为0.9667和0.9481，超越了现有最优模型140%以上，展示了其在复杂数据关系中的有效性和灵活性。,0
e-person Architecture and Framework for Human-AI Co-adventure Relationship,人机共冒险关系的e-person架构与框架,28 Mar 2025,Other,Other,https://arxiv.org/pdf/2503.22181,https://www.arxiv.org/abs/2503.22181,https://www.alphaxiv.org/abs/2503.22181,本文提出了一种名为e-person架构的框架，旨在促进人机协作中的AI伦理的统一和渐进发展。该架构通过分类和定义不确定性，基于第一、第二和第三人视角以及信息深度的推理难度，提供了伦理发展的基础。作者还基于自由能原理提出了e-person框架，强调通过减少不确定性来实现大脑功能的统一。论文强调，面对AI技术的快速普及，需从工程角度系统性地解决伦理问题，而非仅仅拆分为多个独立问题。这一工作为AI伦理的实践和发展提供了新的视角和方法。,0
When Autonomy Breaks: The Hidden Existential Risk of AI,当自主性崩溃时：人工智能的隐性生存风险,28 Mar 2025,AGI,Other,https://arxiv.org/pdf/2503.22151,https://www.arxiv.org/abs/2503.22151,https://www.alphaxiv.org/abs/2503.22151,论文《当自主权崩溃时：人工智能的隐性生存风险》探讨了人工智能对人类自主权的潜在威胁。作者认为，随着AI在各个领域逐渐超越人类，可能导致人类决策、创造力和社会关怀等能力的逐步丧失。这种“去技能化”过程将使人类愈发依赖AI，最终可能使人类的生活被技术所主导，失去自主决策的能力。论文强调，最大的风险并非机器变得更像人类，而是人类变得更像机器，呼吁对这一隐性风险进行更多关注和研究。,0
