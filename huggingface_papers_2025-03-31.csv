标题,中文标题,领域分类,研究机构,PDF链接,论文链接,简明摘要,Upvote数
"AdaptiVocab: Enhancing LLM Efficiency in Focused Domains through
  Lightweight Vocabulary Adaptation",AdaptiVocab：通过轻量级词汇适应提升专注领域中的大语言模型效率,LLM,Other,https://arxiv.org/pdf/2503.19693,https://huggingface.co/papers/2503.19693,本文介绍了一种名为AdaptiVocab的创新方法，旨在通过轻量级词汇适应提升大型语言模型（LLMs）在特定领域的效率。AdaptiVocab通过用领域特定的n-gram代替通用词汇，减少输入处理和输出生成所需的标记数量，从而降低延迟和计算成本。该方法可适用于任何分词器和模型架构，并在单个GPU上高效进行轻量级微调。实验结果显示，AdaptiVocab在三个小众领域中成功将标记使用量减少超过25%，同时保持生成质量和任务性能，展示了其在低资源环境下的有效性。,31
"Exploring Data Scaling Trends and Effects in Reinforcement Learning from
  Human Feedback",探索人类反馈强化学习中的数据缩放趋势与影响,LLM,ByteDance,https://arxiv.org/pdf/2503.22230,https://huggingface.co/papers/2503.22230,本论文探讨了人类反馈强化学习（RLHF）中数据构建对性能扩展的影响，强调了奖励黑客和响应多样性下降等数据驱动瓶颈。为解决这些问题，提出了一种结合推理任务验证器（RTV）和生成奖励模型（GenRM）的混合奖励系统，以减轻奖励黑客的影响。此外，提出了新颖的提示选择方法Pre-PPO，以保持响应多样性并提高学习效果。研究发现，优先考虑数学和编码任务能显著提升早期训练表现。通过在两种模型规模上的实验验证了这些方法的有效性，强调了精心的数据构建在RLHF中的重要性。,21
"Think Before Recommend: Unleashing the Latent Reasoning Power for
  Sequential Recommendation",在推荐之前思考：释放序列推荐的潜在推理能力,Other,Alibaba,https://arxiv.org/pdf/2503.22675,https://huggingface.co/papers/2503.22675,本论文提出了ReaRec，一个创新的推理框架，旨在提高序列推荐系统的性能。传统方法通常依赖于直接的前向计算，导致对用户偏好的复杂演变和长尾项目的理解不足。ReaRec通过隐式多步推理增强用户表示，结合特殊的推理位置嵌入，解耦原始项目编码和推理空间。此外，论文引入了两种轻量级的推理学习方法（ERL和PRL）以进一步挖掘推理潜力。实验证明，ReaRec在多个公共数据集上显著提升了推荐系统的性能，提升幅度达30%-50%，为未来的序列推荐研究开辟了新方向。,20
"A Survey of Efficient Reasoning for Large Reasoning Models: Language,
  Multimodality, and Beyond",大型推理模型高效推理的调查：语言、多模态及其他,Multimodal LLM,"Shanghai AI Lab, PKU",https://arxiv.org/pdf/2503.21614,https://huggingface.co/papers/2503.21614,本文对大型推理模型（LRMs）在推理效率方面的挑战进行了全面调查。尽管近期LRMs在推理过程中通过扩展思维链（CoT）长度取得了显著性能提升，但它们往往生成冗长且重复的推理过程，导致训练和实际应用中的效率问题。论文识别了这些低效模式，并回顾了从预训练到推理的不同阶段所提出的改进方法。研究还探讨了未来的研究方向，并维护了一个实时更新的GitHub库，以支持该领域的持续发展。此调查为进一步探索和创新奠定了基础。,16
ORIGEN: Zero-Shot 3D Orientation Grounding in Text-to-Image Generation,ORIGEN：文本到图像生成中的零-shot 3D方向定位,Diffusion Model,Other,https://arxiv.org/pdf/2503.22194,https://huggingface.co/papers/2503.22194,本文提出了ORIGEN，这是首个在文本到图像生成中实现零-shot 3D方向定位的方法，能够处理多个对象和多样化类别。与以往主要关注2D位置的空间定位研究不同，ORIGEN通过采用预训练的判别模型进行3D方向估计，结合一种基于奖励引导的采样方法，克服了对图像真实感的挑战。通过引入Langevin动力学和自适应时间重缩放，ORIGEN在多个量化指标和用户研究中超越了现有的训练和测试指导方法，展现了其在生成高质量、准确对齐图像方面的优势。,14
"Free4D: Tuning-free 4D Scene Generation with Spatial-Temporal
  Consistency",Free4D：无调优的具有时空一致性的4D场景生成,Diffusion Model,Other,https://arxiv.org/pdf/2503.20785,https://huggingface.co/papers/2503.20785,论文提出了Free4D，一个无需调优的框架，能够从单张图像生成4D场景。与现有方法不同，Free4D不依赖于大规模多视角视频数据，而是利用预训练的基础模型来实现一致的4D场景表示。该方法首先通过图像到视频的扩散模型对输入图像进行动画处理，然后采用自适应引导机制和新颖的潜在替换策略，确保生成视频在空间和时间上的一致性。最终，结合调制基础的细化技术，Free4D实现了实时、可控的4D渲染，显著推动了基于单图像的4D场景生成研究。,11
"PHYSICS: Benchmarking Foundation Models on University-Level Physics
  Problem Solving",物理学：大学水平物理问题解决的基础模型基准测试,LLM,Other,https://arxiv.org/pdf/2503.21821,https://huggingface.co/papers/2503.21821,本文介绍了PHYSICS，一个针对大学水平物理问题解决的全面基准测试，涵盖了1297个专家注释的问题，涉及经典力学、量子力学、热力学与统计力学、电磁学、原子物理和光学六个核心领域。研究开发了一个自动化评估系统，以确保精确可靠的验证。对领先的基础模型的评估显示出显著的局限性，最先进的模型o3-mini的准确率仅为59.9%。通过错误分析和多样化的提示策略探索，本文识别了改进的关键领域，为未来的进展奠定了基础。,10
"Hi3DGen: High-fidelity 3D Geometry Generation from Images via Normal
  Bridging",Hi3DGen：通过法线桥接从图像生成高保真3D几何体,Diffusion Model,"ByteDance, THU",https://arxiv.org/pdf/2503.22236,https://huggingface.co/papers/2503.22236,本文提出了Hi3DGen，一个新颖的框架，通过法线桥接技术从2D图像生成高保真3D几何模型。该框架包含三个核心组件：图像到法线估计器、法线到几何学习方法，以及3D数据合成管道。通过噪声注入和双流训练，图像到法线估计器实现了稳定且清晰的估计；法线正则化的潜在扩散学习提高了3D几何生成的保真度。实验结果显示，Hi3DGen在生成细致的几何细节方面优于现有最先进的方法，为高保真3D几何生成提供了新的研究方向。,9
Segment Any Motion in Videos,视频中任意运动的分割,Other,PKU,https://arxiv.org/pdf/2503.22268,https://huggingface.co/papers/2503.22268,本论文提出了一种新颖的移动对象分割方法，旨在提高视频中运动物体的识别精度。该方法结合了长距离轨迹运动线索与基于DINO的语义特征，并利用SAM2进行像素级掩膜细化。通过引入时空轨迹注意力和运动-语义解耦嵌入，模型在优先考虑运动的同时整合了语义信息。经过在多样化数据集上的广泛测试，结果表明该方法在复杂场景和多对象细分中表现出色，达到了最先进的性能。这一研究为视频分析及相关应用提供了重要的技术支持。,7
"4D-Bench: Benchmarking Multi-modal Large Language Models for 4D Object
  Understanding",4D-Bench：多模态大语言模型在4D物体理解中的基准测试,Multimodal LLM,Other,https://arxiv.org/pdf/2503.17827,https://huggingface.co/papers/2503.17827,本文介绍了4D-Bench，这是首个用于评估多模态大型语言模型（MLLMs）在4D物体理解能力的基准。4D物体是指具有时间演变的3D物体，4D-Bench包括4D物体问答和4D物体描述等任务，提供多样化的4D物体类别和高质量注释。实验结果显示，MLLMs在时间理解方面表现较弱，尤其是开源模型在外观理解上接近闭源模型，但在时间理解上差距更大。此外，即使在简单的单对象视频中，MLLMs的表现也远低于人类基线，显示出4D物体理解领域的显著差距和进一步发展的必要性。,6
A Refined Analysis of Massive Activations in LLMs,大语言模型中大规模激活的精细分析,LLM,Other,https://arxiv.org/pdf/2503.22329,https://huggingface.co/papers/2503.22329,本论文对大型语言模型（LLMs）中的“巨大激活”现象进行了深入分析，填补了现有研究的局限。研究发现，并非所有巨大激活都是有害的，抑制它们并不会导致困惑度剧增或下游任务性能崩溃。此外，现有的缓解策略如Attention KV偏置在某些情况下效果不佳，因此提出了新型混合缓解策略。特别是，将目标方差重标定（TVR）与Attention KV偏置或动态Tanh（DyT）结合使用，能够有效减轻巨大激活的影响，同时保持下游模型性能。这些发现对模型优化和部署具有重要的实际意义。,5
SparseFlex: High-Resolution and Arbitrary-Topology 3D Shape Modeling,SparseFlex: 高分辨率和任意拓扑的3D形状建模,Other,THU,https://arxiv.org/pdf/2503.21732,https://huggingface.co/papers/2503.21732,本论文提出了SparseFlex，一种新颖的稀疏结构等值面表示方法，旨在解决高保真3D网格建模中面临的挑战，尤其是开放表面和复杂内部结构。SparseFlex支持高达1024^3的分辨率，通过渲染损失实现可微分的网格重建。论文引入了一种基于视锥的分层体素训练策略，显著降低了内存消耗并提高了训练效率，首次实现了仅通过渲染监督重建网格内部。通过训练变分自编码器和修正流变换器，SparseFlex在3D形状生成上表现出色，重建精度达到领先水平，推动了3D形状表示与建模的前沿发展。,4
"Semantic Library Adaptation: LoRA Retrieval and Fusion for
  Open-Vocabulary Semantic Segmentation",语义库适应：基于LoRA的检索与融合用于开放词汇语义分割,Other,Other,https://arxiv.org/pdf/2503.21780,https://huggingface.co/papers/2503.21780,本文提出了一种新颖的框架——语义库适应（SemLA），用于开放词汇语义分割的无训练、测试时域适应。SemLA利用基于LoRA的适配器库，并通过CLIP嵌入动态合并与目标域最相关的适配器，从而为每个特定输入构建量身定制的模型，而无需额外训练。该方法提高了模型的适应能力和可解释性，同时保护数据隐私，适合敏感应用。通过在20个领域的基准测试中进行的全面实验，SemLA在多种设置下展现了卓越的性能，确立了开放词汇语义分割领域适应的新标准。,3
"ReFeed: Multi-dimensional Summarization Refinement with Reflective
  Reasoning on Feedback",ReFeed：基于反馈的多维摘要精炼与反思推理,LLM,Amazon,https://arxiv.org/pdf/2503.21332,https://huggingface.co/papers/2503.21332,本论文提出了ReFeed，一个多维度摘要精炼管道，通过对反馈进行反思性推理来提升摘要质量。研究中发布了SumFeed-CoT，一个基于Long-CoT的大规模数据集，旨在训练轻量级模型以进行有效的反思推理。实验表明，维度数量、反馈暴露和推理策略对精炼效果有显著影响，强调了同时处理多种反馈的重要性，以减轻维度间的权衡。此外，ReFeed对噪声反馈和反馈顺序具有鲁棒性，研究结果还表明，创建具有明确目标和指导的数据是有效推理的基础。该数据集和模型将被公开发布。,3
"MedAgent-Pro: Towards Multi-modal Evidence-based Medical Diagnosis via
  Reasoning Agentic Workflow",MedAgent-Pro：基于证据的多模态医学诊断的推理智能工作流程,Multimodal LLM,Other,https://arxiv.org/pdf/2503.18968,https://huggingface.co/papers/2503.18968,本论文提出了MedAgent-Pro，一个基于证据的多模态医疗诊断系统，旨在提高医疗诊断的可靠性和解释性。该系统通过层级工作流程，结合知识驱动的推理和多工具代理，处理多种输入，分析关键指标，从而生成精准的诊断结果。实验表明，MedAgent-Pro在2D和3D医学诊断任务中表现优越，克服了现有多模态大语言模型在视觉输入处理和推理一致性方面的局限。此研究为医疗AI的应用提供了新的思路，推动了智能诊断技术的发展。,3
"X^{2}-Gaussian: 4D Radiative Gaussian Splatting for Continuous-time
  Tomographic Reconstruction",X^{2}-高斯：用于连续时间断层重建的4D辐射高斯点云,Other,Other,https://arxiv.org/pdf/2503.21779,https://huggingface.co/papers/2503.21779,本文提出了一种名为X²-Gaussian的新框架，旨在实现连续时间的四维计算机断层扫描（4D CT）重建，以克服传统相位分箱方法的局限性。该方法通过动态辐射高斯喷溅和自监督呼吸运动学习相结合，采用时空编码器-解码器架构，预测时间变化的高斯变形，从而消除相位离散化的需求。通过引入生理驱动的周期一致性损失，X²-Gaussian能够直接从投影中学习患者特定的呼吸周期，避免对外部设备的依赖。实验结果表明，该方法在图像质量上显著优于传统技术，推动了动态临床成像的高保真重建。,2
"Tracktention: Leveraging Point Tracking to Attend Videos Faster and
  Better",Tracktention：利用点跟踪加速视频处理并提升效果,Other,Other,https://arxiv.org/pdf/2503.19904,https://huggingface.co/papers/2503.19904,本文提出了一种新颖的Tracktention Layer，旨在提升视频预测中的时间一致性。传统方法在处理动态场景中的显著物体运动时常常面临挑战，而Tracktention Layer通过整合点跟踪信息，显著改善了时间对齐能力，能够有效应对复杂的物体运动。该模块可高效地与现有模型（如视觉变换器）集成，甚至能将图像模型升级为视频模型，且在视频深度预测和视频着色等任务中表现优于专为视频设计的模型。实验结果表明，使用Tracktention Layer的模型在时间一致性方面显著优于基线模型。,1
On Large Multimodal Models as Open-World Image Classifiers,大型多模态模型作为开放世界图像分类器,Multimodal LLM,Other,https://arxiv.org/pdf/2503.21851,https://huggingface.co/papers/2503.21851,本文探讨了大型多模态模型（LMMs）在开放世界图像分类中的表现，挑战了传统图像分类依赖预定义类别的假设。研究通过建立评估协议和多种指标，系统性地评估了13种模型在10个基准数据集上的分类能力，涵盖了不同粒度的类别。结果显示，尽管LMMs在开放世界环境中表现优于对比基础方法，但仍面临粒度和细粒度能力的挑战。研究还提出了通过定制提示和推理来缓解这些问题的方法，为未来的图像分类研究提供了重要的见解和方向。,1
"Perceptually Accurate 3D Talking Head Generation: New Definitions,
  Speech-Mesh Representation, and Evaluation Metrics",感知准确的3D说话头生成：新定义、语音网格表示和评估指标,Other,Other,https://arxiv.org/pdf/2503.20308,https://huggingface.co/papers/2503.20308,本论文提出了一种新的3D说话头生成方法，旨在提高唇部动作与语音的感知一致性。研究者定义了三个关键标准：时间同步、唇部可读性和表现力，以评估唇部动作的感知准确性。为满足这些标准，作者引入了一种新的“语音-网格同步”表示法，捕捉语音信号与3D面部网格之间的复杂对应关系。实验表明，将这一表示法作为感知损失应用于现有模型显著改善了唇部同步的各个方面。此外，作者还提出了两种物理基础的评估指标，以量化生成的3D说话头的表现。,1
Your ViT is Secretly an Image Segmentation Model,你的ViT实际上是一个图像分割模型,Other,Other,https://arxiv.org/pdf/2503.19108,https://huggingface.co/papers/2503.19108,本论文提出了一种新的图像分割模型——编码器仅掩码变换器（EoMT），旨在利用视觉变换器（ViT）架构进行图像分割。研究表明，ViT可以在充分大的模型和广泛预训练的情况下，自主学习任务特定的偏置，而无需依赖复杂的卷积适配器和解码器。EoMT在分割精度上与现有最先进模型相当，但由于其简化的结构，速度提升显著（如ViT-L可快4倍）。该方法在不同模型规模上实现了分割精度与预测速度的最佳平衡，表明资源应更多投入于ViT的扩展，而非增加架构复杂性。,1
Reconstructing Humans with a Biomechanically Accurate Skeleton,用生物力学精确骨架重建人类,Embodied AI,Other,https://arxiv.org/pdf/2503.21751,https://huggingface.co/papers/2503.21751,本文提出了一种从单张图像重建3D人类模型的方法，采用生物力学准确的骨骼模型。通过训练一个变换器，该方法能够估计模型参数。由于训练数据的缺乏，研究者构建了一个生成伪真实标签的管道，并实施了迭代优化的训练程序。与现有的3D人体网格恢复方法相比，该模型在标准基准测试中表现出色，尤其在极端姿势和视角下具有显著优势。此外，本文的方法遵循生物力学约束，避免了关节角度限制的违反，从而实现更自然的关节旋转估计。研究结果在多个人体姿态估计基准上得到了验证，相关代码和数据已公开。,0
