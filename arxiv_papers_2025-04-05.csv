标题,中文标题,发布日期,领域分类,研究机构,PDF链接,论文链接,AlphaXiv链接,简明摘要,点赞数
Adaptive Rectification Sampling for Test-Time Compute Scaling,测试时计算缩放的自适应修正采样,02 Apr 2025,LLM,Other,https://arxiv.org/pdf/2504.01317,https://www.arxiv.org/abs/2504.01317,https://www.alphaxiv.org/abs/2504.01317,本文提出了一种名为自适应修正采样（AR-Sampling）的方法，以提高大型语言模型（LLMs）在测试时的推理能力。AR-Sampling利用过程监督奖励模型（PRM）作为验证器，指导模型在适当的时刻进行细致的自我修正，从而减少冗余的输出和提升可读性。通过在GSM8K和MATH500数据集上的实验，结果表明，该方法不仅提高了模型的解题准确性，还有效减少了生成的额外标记数量。该研究为解决模型在推理过程中可能出现的“过度思考”问题提供了新思路。,24
"Review, Refine, Repeat: Understanding Iterative Decoding of AI Agents with Dynamic Evaluation and Selection",审查、完善、重复：理解具有动态评估和选择的AI智能体的迭代解码,02 Apr 2025,Agent,Other,https://arxiv.org/pdf/2504.01931,https://www.arxiv.org/abs/2504.01931,https://www.alphaxiv.org/abs/2504.01931,本论文提出了一种新的迭代解码方法——迭代代理解码（IAD），旨在提升AI代理在复杂多模态任务中的表现。与传统的最佳选择（BON）采样方法相比，IAD结合了动态候选评估和选择，通过引入反馈机制优化了生成过程。研究表明，IAD在Sketch2Code、Text2SQL和Webshop等任务中均显著超越了基线模型，取得3-10%的绝对性能提升。实验结果表明，IAD的改进主要源于验证者引导的精细化过程，而非仅仅依赖于采样多样性。这项研究为AI代理的推理优化提供了重要见解，强调了验证者质量在提升性能中的关键作用。,21
"Scaling Test-Time Inference with Policy-Optimized, Dynamic Retrieval-Augmented Generation via KV Caching and Decoding",通过KV缓存和解码的策略优化动态检索增强生成的测试时间推理扩展,02 Apr 2025,LLM,Other,https://arxiv.org/pdf/2504.01281,https://www.arxiv.org/abs/2504.01281,https://www.alphaxiv.org/abs/2504.01281,本文提出了一种增强检索增强生成（RAG）系统的框架，通过动态检索策略和强化学习微调显著提升大语言模型在知识密集型任务中的表现。核心技术包括优化检索信息利用的政策优化检索增强生成（PORAG）和基于上下文需求的自适应令牌层注意力评分（ATLAS）。该框架兼容任何基于Transformer的语言模型，无需额外训练，显著提高了输出的准确性和响应质量。此外，提出的CRITIC方法通过重要性选择性压缩键值缓存，缓解了长上下文应用中的内存瓶颈。实验结果显示，该框架在减少幻觉、增强领域特定推理和提升效率方面优于传统RAG系统。,13
Medical large language models are easily distracted,医学大语言模型容易分心,01 Apr 2025,LLM,Other,https://arxiv.org/pdf/2504.01201,https://www.arxiv.org/abs/2504.01201,https://www.alphaxiv.org/abs/2504.01201,这篇论文探讨了医疗大型语言模型（LLMs）在面对临床场景中的干扰信息时的表现。研究开发了MedDistractQA基准，通过在USMLE风格的问题中嵌入模拟的干扰信息，评估LLMs的抗干扰能力。结果显示，干扰信息会使模型的准确性降低多达17.9%。常见的改进方法，如检索增强生成（RAG）和医学微调，未能有效改善这一问题，反而可能引入新的混淆因素。研究表明，LLMs缺乏有效过滤相关与无关信息的能力，强调了在真实医疗应用中需要更强的抗干扰策略。,9
