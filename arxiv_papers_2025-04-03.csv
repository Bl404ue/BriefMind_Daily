标题,中文标题,发布日期,领域分类,研究机构,PDF链接,论文链接,AlphaXiv链接,简明摘要,点赞数
Reasoning LLMs for User-Aware Multimodal Conversational Agents,面向用户感知的多模态对话智能体的推理大语言模型,02 Apr 2025,Multimodal LLM,Other,https://arxiv.org/pdf/2504.01700,https://www.arxiv.org/abs/2504.01700,https://www.alphaxiv.org/abs/2504.01700,本论文提出了一种名为USER-LLM R1的框架，以解决社交机器人中的个性化问题，特别是应对初始用户偏好缺失的“冷启动”挑战。该框架结合了链式推理模型和视觉语言模型，通过动态用户画像和多模态输入，实现从首次互动开始的个性化交流。研究表明，该系统在ElderlyTech-VQA基准测试中显著提高了生成响应的质量，特别是在老年用户中增强了互动的参与感和信任度。此外，论文还探讨了隐私保护和偏见缓解等伦理问题，确保系统的负责任部署。,0
Adaptive Rectification Sampling for Test-Time Compute Scaling,测试时计算缩放的自适应修正采样,02 Apr 2025,LLM,Other,https://arxiv.org/pdf/2504.01317,https://www.arxiv.org/abs/2504.01317,https://www.alphaxiv.org/abs/2504.01317,本论文提出了一种新的方法——自适应修正采样（AR-Sampling），旨在提高大语言模型（LLMs）在测试时的推理能力。通过利用过程监督奖励模型（PRM）作为验证器，AR-Sampling能够在适当的时刻引导模型进行细致的自我修正，从而减少冗余的生成令牌并提高输出的准确性。实验结果表明，该方法在GSM8K和MATH500数据集上有效提升了模型的解决方案准确性，同时避免了过度思考的问题。该研究为测试时计算资源的优化和模型性能的提升提供了新的思路。,0
"Scaling Test-Time Inference with Policy-Optimized, Dynamic Retrieval-Augmented Generation via KV Caching and Decoding",通过KV缓存和解码的策略优化动态检索增强生成的测试时推理扩展,02 Apr 2025,LLM,Other,https://arxiv.org/pdf/2504.01281,https://www.arxiv.org/abs/2504.01281,https://www.alphaxiv.org/abs/2504.01281,本论文提出了一种增强检索增强生成（RAG）系统的综合框架，通过动态检索策略和强化学习微调显著提升大语言模型在知识密集型任务中的表现。核心技术包括政策优化的检索增强生成（PORAG）和自适应令牌层注意力评分（ATLAS），优化了检索信息的使用及其相关性。此外，论文引入了CRITIC方法，选择性地压缩关键值缓存以缓解长上下文应用中的内存瓶颈。实验结果表明，该框架在减少幻觉、增强领域特定推理和提升效率方面，相较于传统RAG系统表现出显著优势，推动了RAG系统在多种应用中的发展。,0
Advancing AI-Scientist Understanding: Making LLM Think Like a Physicist with Interpretable Reasoning,推进AI-科学家理解：使大语言模型以可解释的推理方式思考物理学,02 Apr 2025,Other,Other,https://arxiv.org/pdf/2504.01911,https://www.arxiv.org/abs/2504.01911,https://www.alphaxiv.org/abs/2504.01911,本文提出了一种新框架，旨在提高大型语言模型（LLMs）在物理研究中的可解释性和可靠性。通过引入一个解释模块，该模块由多个专门代理组成，协助人类科学家理解和验证LLM生成的输出。研究强调，物理推理需要严格的逻辑一致性和定量精确性，因此该模块将物理模型作为可解释的界面，使得科学家能够更直观地与AI成果互动。案例研究表明，该方法增强了透明度，促进了验证，并加强了AI辅助的科学发现能力。,0
Spatial-R1: Enhancing MLLMs in Video Spatial Reasoning,Spatial-R1：增强视频空间推理中的多模态大语言模型,02 Apr 2025,Multimodal LLM,PKU,https://arxiv.org/pdf/2504.01805,https://www.arxiv.org/abs/2504.01805,https://www.alphaxiv.org/abs/2504.01805,论文《Spatial-R1: Enhancing MLLMs in Video Spatial Reasoning》提出了一种新方法，旨在提升多模态大型语言模型（MLLMs）在视频空间推理中的能力。主要贡献包括构建了一个名为SR的新视频空间推理数据集，包含七类任务的自动生成问答对，以及采用任务特定的相对策略优化（GRPO）进行模型微调。通过在SR数据集上训练Qwen2.5-VL-7B-Instruct模型，Spatial-R1在VSI-Bench基准测试中显著提高了性能，超越了现有强模型，验证了针对性数据和优化技术在复杂空间推理中的有效性。,0
InfiniteICL: Breaking the Limit of Context Window Size via Long Short-term Memory Transformation,InfiniteICL：通过长短期记忆转换突破上下文窗口大小的限制,02 Apr 2025,LLM,Other,https://arxiv.org/pdf/2504.01707,https://www.arxiv.org/abs/2504.01707,https://www.alphaxiv.org/abs/2504.01707,论文《InfiniteICL: Breaking the Limit of Context Window Size via Long Short-term Memory Transformation》提出了一种新框架InfiniteICL，以解决大型语言模型在超长上下文中的有限上下文窗口限制。该方法借鉴人类的短期和长期记忆，将临时上下文知识转化为永久参数更新，从而显著降低内存使用并保持在不同输入长度下的性能。评估结果显示，该方法在减少90%上下文长度的同时，平均性能提升至103%，并在处理复杂的、多轮对话时表现优于传统方法。InfiniteICL的提出为大型语言模型的可扩展性和效率提升提供了新的可能性。,0
ToM-RL: Reinforcement Learning Unlocks Theory of Mind in Small LLMs,ToM-RL：强化学习解锁小型大语言模型中的心智理论,02 Apr 2025,LLM,PKU,https://arxiv.org/pdf/2504.01698,https://www.arxiv.org/abs/2504.01698,https://www.alphaxiv.org/abs/2504.01698,本文提出了一种名为ToM-RL的方法，通过强化学习（RL）显著提升小型语言模型（LLMs）在理论心智（ToM）推理任务中的表现。研究表明，在仅使用3200个多样化场景的问题集进行训练后，7B参数的模型在Hi-ToM基准测试中达到了84.50%的准确率，超越了GPT-4o和DeepSeek-v3等更大模型。尽管较小的模型在推理能力上出现了崩溃，但7B模型通过稳定的信念追踪保持了良好的性能。此外，该模型在面对更复杂的ToM问题和新颖的文本形式时表现出强大的泛化能力，展示了RL在提升社交认知推理方面的潜力。,0
AI-Newton: A Concept-Driven Physical Law Discovery System without Prior Physical Knowledge,AI-Newton：一种无先验物理知识的概念驱动物理定律发现系统,02 Apr 2025,Other,PKU,https://arxiv.org/pdf/2504.01538,https://www.arxiv.org/abs/2504.01538,https://www.alphaxiv.org/abs/2504.01538,论文提出了AI-Newton，一个无需先验物理知识的概念驱动物理定律发现系统。该系统能够从原始数据中自主推导物理定律，集成了知识库和基于物理概念的知识表示。作为概念验证，AI-Newton成功地从带噪声的实验数据中重新发现了牛顿第二定律、能量守恒定律和万有引力定律等基本规律。这一成果标志着向AI驱动的自主科学发现迈出了重要一步，展示了AI在处理复杂科学问题中的潜力。,0
VideoScene: Distilling Video Diffusion Model to Generate 3D Scenes in One Step,VideoScene：提炼视频扩散模型以一步生成3D场景,02 Apr 2025,Diffusion Model,THU,https://arxiv.org/pdf/2504.01956,https://www.arxiv.org/abs/2504.01956,https://www.alphaxiv.org/abs/2504.01956,本文提出了VideoScene，一种新颖的视频蒸馏框架，旨在通过有效的一步生成3D场景，解决从稀疏视图恢复3D场景的挑战。传统方法在输入视图重叠不足时表现不佳，而VideoScene利用大型预训练视频扩散模型，采用3D感知跃迁流蒸馏策略，显著提高了生成速度和质量。该方法通过动态去噪策略优化推理过程，克服了以往模型的时间效率低和缺乏3D约束的问题。实验结果表明，VideoScene在3D场景生成方面优于现有技术，展示了其在未来视频到3D应用中的潜力。,0
ILLUME+: Illuminating Unified MLLM with Dual Visual Tokenization and Diffusion Refinement,ILLUME+: 通过双视觉标记化和扩散精炼照亮统一的多模态大语言模型,02 Apr 2025,Multimodal LLM,Other,https://arxiv.org/pdf/2504.01934,https://www.arxiv.org/abs/2504.01934,https://www.alphaxiv.org/abs/2504.01934,论文介绍了ILLUME+，一种增强版的统一多模态大语言模型（MLLM），通过双视觉标记化和扩散解码器提升了深度语义理解和高保真图像生成能力。与现有模型相比，ILLUME+能够同时处理理解、生成和编辑三大功能，克服了传统模型在图像编辑时的纹理保留不足问题。其创新的双视觉标记器（DualViTok）结合了细致纹理和文本对齐语义，支持动态分辨率的上下文感知图像编辑和生成。ILLUME+在多模态理解和生成任务中表现优异，为未来多模态模型应用奠定了坚实基础。,0
BOGausS: Better Optimized Gaussian Splatting,BOGausS: 更优优化的高斯溅射,02 Apr 2025,Other,Other,https://arxiv.org/pdf/2504.01844,https://www.arxiv.org/abs/2504.01844,https://www.alphaxiv.org/abs/2504.01844,论文《BOGausS: Better Optimized Gaussian Splatting》提出了一种改进的3D高斯渲染方法，旨在提高模型的效率和质量。研究者通过分析3D高斯渲染的训练过程，提出了一种新的优化方法，使得生成的模型在保持高质量的同时，体积可缩小至原来的十分之一。该方法引入了改进的稀疏Adam优化器和基于失真率优化的高斯密度保持机制，从而在不同场景和视角下实现更优的重建效果。实验结果表明，BOGausS在多个基准数据集上表现优于现有技术，显著提升了性能。,0
FlowR: Flowing from Sparse to Dense 3D Reconstructions,FlowR：从稀疏到密集的3D重建,02 Apr 2025,Other,Meta,https://arxiv.org/pdf/2504.01647,https://www.arxiv.org/abs/2504.01647,https://www.alphaxiv.org/abs/2504.01647,论文《FlowR: Flowing from Sparse to Dense 3D Reconstructions》提出了一种新颖的多视角流匹配模型，旨在提高稀疏和密集3D重建的质量。该模型通过学习从稀疏重建生成的视图到理想密集重建视图之间的流动，从而增强场景捕捉的效果。与以往仅依赖少量参考视图的生成模型不同，FlowR充分利用了可用的3D信息，显著改善了重建质量。研究基于一个包含360万对图像的新数据集进行训练，展示了在多个新视图合成基准测试中优于现有方法的性能。该方法为虚拟现实等应用提供了更高质量的3D重建解决方案。,0
Generative Retrieval and Alignment Model: A New Paradigm for E-commerce Retrieval,生成检索与对齐模型：电子商务检索的新范式,02 Apr 2025,LLM,Other,https://arxiv.org/pdf/2504.01403,https://www.arxiv.org/abs/2504.01403,https://www.alphaxiv.org/abs/2504.01403,本文提出了一种新的电子商务检索范式——生成检索与对齐模型（GRAM），旨在解决传统稀疏和密集检索方法在利用世界知识与捕捉查询和产品细微特征方面的不足。GRAM通过联合训练查询和产品的文本信息，生成共享的文本标识符，增强了查询与产品之间的关联性，提高了检索效率。此外，模型引入了查询-产品评分机制，优化了检索和预排序过程。大量离线和在线测试表明，GRAM在检索性能上显著优于传统方法和最新的生成检索模型，验证了其有效性和实用性。,0
De Novo Molecular Design Enabled by Direct Preference Optimization and Curriculum Learning,通过直接偏好优化和课程学习实现的全新分子设计,02 Apr 2025,Other,Other,https://arxiv.org/pdf/2504.01389,https://www.arxiv.org/abs/2504.01389,https://www.alphaxiv.org/abs/2504.01389,本论文提出了一种新颖的分子设计方法，结合了直接偏好优化（DPO）和课程学习，旨在提高药物发现的效率。传统的分子筛选方法耗时且成本高，而DPO通过优化高低质量分子的配对样本，显著提升了模型的训练效率和收敛速度。实验结果表明，该方法在GuacaMol基准测试中表现优异，特别是在Perindopril MPO任务中取得了6%的性能提升。此外，后续的靶蛋白结合实验验证了其实际应用效果，展示了DPO在数据驱动药物发现中的潜力和有效性。,0
3D Gaussian Inverse Rendering with Approximated Global Illumination,带有近似全局光照的3D高斯逆渲染,02 Apr 2025,Other,Other,https://arxiv.org/pdf/2504.01358,https://www.arxiv.org/abs/2504.01358,https://www.alphaxiv.org/abs/2504.01358,本论文提出了一种新颖的3D高斯逆渲染方法，结合了屏幕空间光线追踪技术，以实现高效的全局光照。通过对3D高斯模型的直接照明进行增强，该方法能够捕捉间接光照，从而提升场景的真实感和可编辑性。与传统方法相比，该技术不仅支持实时渲染和编辑，还解决了以往只考虑直接光照的局限。实验结果表明，作者的方法在保持计算效率的同时，显著改善了场景的光照效果，适用于物理基础的渲染和场景编辑。,0
MuTri: Multi-view Tri-alignment for OCT to OCTA 3D Image Translation,MuTri：用于OCT到OCTA三维图像翻译的多视角三重对齐,02 Apr 2025,Other,Other,https://arxiv.org/pdf/2504.01428,https://www.arxiv.org/abs/2504.01428,https://www.alphaxiv.org/abs/2504.01428,本论文提出了一种名为MuTri的多视角三重对齐框架，用于将光学相干断层扫描（OCT）图像转换为光学相干断层扫描血管成像（OCTA）图像。现有方法多依赖单一视角，导致效果不佳。MuTri通过预训练向量量化变分自编码器（VQ-VAE）来建立语义先验，并利用多视角对齐策略优化OCT到OCTA的映射，显著提高了图像翻译的质量。此外，研究收集了首个大规模数据集OCTA2024，包含846个受试者的OCT和OCTA体积数据，为进一步研究提供了基础。,0
"Review, Refine, Repeat: Understanding Iterative Decoding of AI Agents with Dynamic Evaluation and Selection",审查、完善、重复：理解具有动态评估和选择的AI智能体的迭代解码,02 Apr 2025,Agent,Other,https://arxiv.org/pdf/2504.01931,https://www.arxiv.org/abs/2504.01931,https://www.alphaxiv.org/abs/2504.01931,本论文提出了一种名为迭代代理解码（IAD）的方法，旨在提高人工智能代理在复杂多模态任务中的表现。与传统的最佳响应生成方法（BON）相比，IAD结合了动态候选评估和选择，通过引入反馈机制进行迭代优化。研究表明，IAD在多个任务（如Sketch2Code、Text2SQL和Webshop）中均表现优于基线，取得了3-10%的绝对性能提升。通过控制实验，论文揭示了反馈质量在推理时间优化中的关键作用，强调了优化过程中评估者的质量对性能的影响。这些发现为有效的推理优化提供了重要见解。,0
An Illusion of Progress? Assessing the Current State of Web Agents,进步的幻觉？评估网络智能体的当前状态,02 Apr 2025,Agent,Other,https://arxiv.org/pdf/2504.01382,https://www.arxiv.org/abs/2504.01382,https://www.alphaxiv.org/abs/2504.01382,本论文评估了当前网络代理的能力，揭示了先前研究中存在的过度乐观现象。作者提出了一个新的在线评估基准——Online-Mind2Web，涵盖300个多样化的任务，以更真实地反映用户使用代理的场景。研究表明，许多最新的网络代理在该基准上的表现不如早期的简单代理，突显了现有评估方法的不足。此外，论文还开发了一种新的自动评估方法，能与人类判断达成约85%的一致性。通过全面比较当前网络代理的优缺点，本文为未来研究提供了重要参考。,0
Critical Thinking: Which Kinds of Complexity Govern Optimal Reasoning Length?,批判性思维：哪种复杂性决定最佳推理长度？,02 Apr 2025,LLM,Other,https://arxiv.org/pdf/2504.01935,https://www.arxiv.org/abs/2504.01935,https://www.alphaxiv.org/abs/2504.01935,本论文探讨了大型语言模型（LLMs）在推理过程中使用额外推理步骤的有效性，提出了一种基于确定性有限自动机（DFA）的框架来分析任务复杂性。研究发现，存在一种最佳推理步骤数量（称为“临界长度”），在此数量下，模型的准确性达到峰值。论文进一步指出，任务的运行长度与临界长度呈正相关，而状态空间大小则与之无明显关系。通过预测临界长度并筛选非最佳长度的答案，研究表明可以显著提高模型的准确性。这些发现为优化LLMs的推理策略提供了实用见解。,0
Cross-Lingual Consistency: A Novel Inference Framework for Advancing Reasoning in Large Language Models,跨语言一致性：推动大语言模型推理的新颖推理框架,02 Apr 2025,LLM,Other,https://arxiv.org/pdf/2504.01857,https://www.arxiv.org/abs/2504.01857,https://www.alphaxiv.org/abs/2504.01857,本文提出了一种新的推理框架——跨语言一致性（CLC），旨在提升大型语言模型（LLMs）的推理能力。CLC通过多语言推理路径的集成和多数投票机制，克服了多语言训练语料中固有的语言偏见和逻辑不一致问题。实验证明，CLC在CMATH数据集上的表现优于传统的自一致性方法，分别为不同模型提供了显著的准确率提升。同时，CLC的多语言扩展不仅中和了语言偏见，还帮助模型在更广泛的多语言解空间中找到更优的推理路径，从而提高了推理的整体准确性。这一创新为复杂推理任务的有效性提供了新的解决方案。,0
OpenThaiGPT 1.6 and R1: Thai-Centric Open Source and Reasoning Large Language Models,OpenThaiGPT 1.6 和 R1：以泰国为中心的开源和推理大语言模型,02 Apr 2025,LLM,Other,https://arxiv.org/pdf/2504.01789,https://www.arxiv.org/abs/2504.01789,https://www.alphaxiv.org/abs/2504.01789,本文介绍了OpenThaiGPT 1.6（OTG-1.6）和OpenThaiGPT R1（OTG-R1），这两款以泰语为中心的大型语言模型，旨在提升模型的泛化和推理能力。OTG-1.6通过任务算术模型合并实现广泛的泛化，而OTG-R1则结合了多阶段训练和“少即是多”推理假设，以增强推理能力。基准评估显示，这两个模型在泰语任务上表现优异，尤其在较小规模下仍能与更大规模的开源模型竞争，标志着泰语语言模型的新标准。论文详细阐述了模型的训练过程、评估基准和结果，展示了其在泰语特定任务上的显著改进。,0
BlenderGym: Benchmarking Foundational Model Systems for Graphics Editing,BlenderGym: 基于基础模型系统的图形编辑基准测试,02 Apr 2025,Multimodal LLM,Other,https://arxiv.org/pdf/2504.01786,https://www.arxiv.org/abs/2504.01786,https://www.alphaxiv.org/abs/2504.01786,本文介绍了BlenderGym，这是首个针对3D图形编辑的视觉语言模型（VLM）基准测试系统。BlenderGym包含245个手工制作的起始-目标场景对，涵盖对象放置、照明调整、材质编辑、形状混合和几何编辑等五个主要任务。该基准旨在评估VLM在自动化图形编辑中的表现，揭示了即使是最先进的VLM系统在某些任务上仍然难以超越人类用户。研究还探讨了推理规模技术对VLM性能的影响，提供了优化推理计算的策略。这为未来的图形编辑自动化研究奠定了基础。,0
Style over Substance: Distilled Language Models Reason Via Stylistic Replication,形式重于内容：蒸馏语言模型通过风格复制进行推理,02 Apr 2025,LLM,Other,https://arxiv.org/pdf/2504.01738,https://www.arxiv.org/abs/2504.01738,https://www.alphaxiv.org/abs/2504.01738,本论文探讨了在知识蒸馏过程中，语言模型如何通过模仿风格化的推理模式来提升其推理能力。研究分析了成功的推理轨迹，识别出结构和词汇模式，并引入了两个新数据集来评估这些模式对蒸馏模型推理能力的影响。结果表明，经过合成风格化轨迹训练的模型表现出可比的性能，甚至在错误答案的情况下仍有提升。这一发现强调了风格模式在提高语言模型推理能力中的重要性，揭示了模型可能更多依赖于表面特征而非深层理解。,0
LLM-mediated Dynamic Plan Generation with a Multi-Agent Approach,基于LLM的动态计划生成与多智能体方法,02 Apr 2025,Agent,Other,https://arxiv.org/pdf/2504.01637,https://www.arxiv.org/abs/2504.01637,https://www.alphaxiv.org/abs/2504.01637,本论文提出了一种基于大型语言模型（LLM）和多智能体系统的动态计划生成方法，旨在提高机器人在动态环境中的适应能力。通过收集环境状态并生成互联的智能体网络，该方法结合了快速反应和深思熟虑的规划能力。与传统手动构建的规划框架相比，所提方法能够自动化计划生成，提供更灵活和通用的解决方案。实验结果表明，自动生成的网络在全面性和适应性上优于手动构建的网络，推动了机器人、自主车辆及智能系统等领域的规划方法发展。,0
Chain of Correction for Full-text Speech Recognition with Large Language Models,基于大语言模型的全文本语音识别纠错链,02 Apr 2025,LLM,"Tencent, THU",https://arxiv.org/pdf/2504.01519,https://www.arxiv.org/abs/2504.01519,https://www.alphaxiv.org/abs/2504.01519,"本文提出了一种名为“纠正链”（Chain of Correction, CoC）的全文本语音识别错误修正方法，旨在利用大型语言模型（LLMs）提高自动语音识别（ASR）的准确性。CoC通过分段纠正错误，并结合预识别文本进行多轮对话，增强了模型对整体语义的理解。研究利用开源的中文全文本错误修正数据集（ChFT）对CoC进行微调，实验结果表明，该方法在纠正ASR输出错误方面显著优于基线系统。本文还探讨了平衡纠正阈值、处理长文本输出及其他信息指导纠正过程的可能性，为ASR系统的错误修正提供了新的思路和方法。",0
OpenCodeReasoning: Advancing Data Distillation for Competitive Coding,OpenCodeReasoning：推进竞争编码的数据蒸馏,02 Apr 2025,LLM,Other,https://arxiv.org/pdf/2504.01943,https://www.arxiv.org/abs/2504.01943,https://www.alphaxiv.org/abs/2504.01943,本文介绍了OpenCodeReasoning，一个旨在提升编程能力的监督微调（SFT）数据集。研究表明，使用该数据集的模型在Live-CodeBench和CodeContests上分别达到了61.8%和24.6%的成绩，超越了依赖强化学习的替代方案。作者分析了数据来源、代码执行过滤的影响以及指令与解决方案多样性的重要性，发现执行过滤会降低基准准确性，因此优先考虑指令多样性。该研究为理解SFT在推理性能提升中的作用提供了新的视角，并展示了合成数据在编码任务中的潜力。,0
STAR-1: Safer Alignment of Reasoning LLMs with 1K Data,STAR-1：基于1K数据的推理大语言模型的更安全对齐,02 Apr 2025,LLM,Other,https://arxiv.org/pdf/2504.01903,https://www.arxiv.org/abs/2504.01903,https://www.alphaxiv.org/abs/2504.01903,本论文介绍了STAR-1，一个专为大型推理模型（LRMs）设计的高质量安全数据集，规模仅为1000条。STAR-1的构建基于多样性、深思熟虑的推理和严格筛选三大原则，旨在提升LRMs的安全对齐能力。通过整合现有的开源安全数据集，生成基于政策的推理样本，并采用GPT-4o的安全评分系统进行训练示例的选择，实验结果表明，使用STAR-1微调LRMs可在四个基准测试中平均提高40%的安全性能，同时仅导致推理能力轻微下降（约1.1%）。该研究为在保持推理能力的同时提升安全性提供了有效的解决方案。,0
GMAI-VL-R1: Harnessing Reinforcement Learning for Multimodal Medical Reasoning,GMAI-VL-R1：利用强化学习进行多模态医学推理,02 Apr 2025,Multimodal LLM,Other,https://arxiv.org/pdf/2504.01886,https://www.arxiv.org/abs/2504.01886,https://www.alphaxiv.org/abs/2504.01886,本文提出了GMAI-VL-R1，一种基于强化学习的多模态医学推理模型，旨在改善复杂医疗决策中的推理能力。与传统的监督微调模型不同，GMAI-VL-R1通过强化学习优化决策过程，显著提高了诊断准确性和临床支持。研究还开发了一种推理数据合成方法，通过拒绝采样生成逐步推理数据，增强模型的泛化能力。实验结果表明，GMAI-VL-R1在医学图像诊断和视觉问答等任务中表现优异，展示了其在高风险临床决策中的潜力，为未来医学推理模型的发展奠定了基础。,0
Interpreting Emergent Planning in Model-Free Reinforcement Learning,无模型强化学习中的新兴规划解释,02 Apr 2025,Agent,Other,https://arxiv.org/pdf/2504.01871,https://www.arxiv.org/abs/2504.01871,https://www.alphaxiv.org/abs/2504.01871,本论文首次提供了模型无关强化学习（RL）代理能够学习内部规划的机制性证据。研究聚焦于Sokoban游戏中的Deep Repeated ConvLSTM（DRC）代理，采用基于概念的可解释性方法，展示了该代理如何利用学习到的概念表示来内部形成计划，从而预测行动的长期效果并影响决策。通过探测规划相关概念、分析计划形成以及验证其对行为的因果影响，研究表明DRC代理的规划行为与并行双向搜索算法相似。这一发现有助于加深对无模型RL代理内部规划机制的理解，推动了对强化学习中新兴规划和推理能力的研究。,0
Medical large language models are easily distracted,医疗大语言模型容易分心,01 Apr 2025,LLM,Other,https://arxiv.org/pdf/2504.01201,https://www.arxiv.org/abs/2504.01201,https://www.alphaxiv.org/abs/2504.01201,这篇论文探讨了医疗大型语言模型（LLMs）在处理真实临床场景中的干扰信息时的脆弱性。研究开发了MedDistractQA基准，通过在美国医学执照考试（USMLE）问题中嵌入模拟干扰，评估模型的准确性。结果显示，干扰信息可导致LLMs的准确率降低多达17.9%。常见的改进策略，如检索增强生成（RAG）和医学微调，未能改善这一问题，反而可能引入新的混淆因素。研究强调了LLMs在过滤相关信息方面的不足，呼吁开发更强健的应对策略，以提高其在临床应用中的可靠性。,0
Diffusion-Guided Gaussian Splatting for Large-Scale Unconstrained 3D Reconstruction and Novel View Synthesis,基于扩散引导的高斯点云用于大规模无约束3D重建和新视角合成,02 Apr 2025,Diffusion Model,Other,https://arxiv.org/pdf/2504.01960,https://www.arxiv.org/abs/2504.01960,https://www.alphaxiv.org/abs/2504.01960,这篇论文提出了一种名为GS-Diff的新框架，旨在解决大规模无约束3D重建和新视角合成中的挑战。GS-Diff结合了多视角扩散模型，通过生成伪观察来改善稀疏数据条件下的3D重建问题。该方法引入了单目深度先验、外观嵌入、动态物体建模和高级光栅化技术等多项增强措施，以应对现实环境中的几何和光度问题。实验结果表明，GS-Diff在多个基准测试中显著优于现有方法，展示了其在复杂场景中的有效性和高保真度。,0
A Unified Approach to Analysis and Design of Denoising Markov Models,去噪马尔可夫模型的分析与设计统一方法,02 Apr 2025,Diffusion Model,Other,https://arxiv.org/pdf/2504.01938,https://www.arxiv.org/abs/2504.01938,https://www.alphaxiv.org/abs/2504.01938,本论文提出了一种统一的方法来分析和设计去噪马尔可夫模型，这是一类基于测度传输的生成模型。作者建立了严谨的数学基础，提出了一系列最小假设，以确保能够显式构建反向生成器，并统一了不同扩散模型的变分目标。该框架识别了去噪马尔可夫模型的一般形式，并提供了基于任意Lévy过程设计模型的系统方法。通过应用几何布朗运动和跳跃过程，展示了该方法在建模复杂分布方面的灵活性和有效性，推动了生成模型在多个领域的应用。,0
Gen-C: Populating Virtual Worlds with Generative Crowds,Gen-C: 用生成性人群填充虚拟世界,02 Apr 2025,Agent,Other,https://arxiv.org/pdf/2504.01924,https://www.arxiv.org/abs/2504.01924,https://www.alphaxiv.org/abs/2504.01924,本文介绍了Gen-C，一个用于自动生成高水平人群行为的框架，旨在丰富虚拟世界中的人群场景。传统的人群模拟主要集中在低层次的运动任务上，而Gen-C通过利用大型语言模型生成初步的人群场景，随后通过模拟扩展这些场景，构建时间扩展图，捕捉代理之间及其与环境的复杂交互。该框架能够根据自然语言描述生成多样化的动态人群行为，展示了在大学校园和火车站等场景中的有效性。Gen-C的创新之处在于减少了对真实人群数据的依赖，使得人群模拟更加灵活和可扩展。,0
Bridging the Linguistic Divide: A Survey on Leveraging Large Language Models for Machine Translation,弥合语言鸿沟：利用大语言模型进行机器翻译的调查,02 Apr 2025,LLM,Other,https://arxiv.org/pdf/2504.01919,https://www.arxiv.org/abs/2504.01919,https://www.alphaxiv.org/abs/2504.01919,本论文综述了大型语言模型（LLMs）在机器翻译（MT）中的应用，特别是针对低资源语言和缺乏平行语料的领域。通过分析少量提示、跨语言迁移和参数高效微调等技术，研究展示了如何在数据稀缺的情况下提升翻译质量。论文还探讨了使用LLMs生成合成数据的方法，并比较了LLM基础的翻译与传统模型的优缺点。此外，作者指出了模型生成中的幻觉、偏见和评估不一致等挑战，提出了未来构建更强大和可扩展的MT系统的方向。这项研究为提高跨语言沟通的包容性提供了实用的见解。,0
Multi-fidelity Parameter Estimation Using Conditional Diffusion Models,基于条件扩散模型的多保真度参数估计,02 Apr 2025,Diffusion Model,Other,https://arxiv.org/pdf/2504.01894,https://www.arxiv.org/abs/2504.01894,https://www.alphaxiv.org/abs/2504.01894,本论文提出了一种基于条件扩散模型的多保真度参数估计方法，用于复杂系统的不确定性量化。该方法通过构建低保真度生成模型，快速近似后验分布，避免了传统方法中需要重复高保真度模型模拟的高计算成本。当需要更高精度时，方法通过自适应精细化来优化参数采样空间，随后训练高保真度生成模型以提高后验分布的准确性。实验结果表明，该方法在多模态密度和等离子体物理应用中表现出色，显著提升了计算效率和准确性。,0
A Diffusion-Based Framework for Occluded Object Movement,基于扩散的遮挡物体运动框架,02 Apr 2025,Diffusion Model,THU,https://arxiv.org/pdf/2504.01873,https://www.arxiv.org/abs/2504.01873,https://www.alphaxiv.org/abs/2504.01873,本论文提出了一种名为DiffOOM的扩散基础框架，旨在解决图像编辑中被遮挡物体的移动问题。该框架通过两个并行分支同时执行物体去遮挡和移动。去遮挡分支利用背景填充策略和动态更新的物体掩膜，专注于完成被遮挡部分；而移动分支则通过潜在优化将完成的物体放置到目标位置，并使用文本引导将物体自然融入新环境。研究表明，DiffOOM在处理被遮挡物体的移动任务中表现优越，具有良好的实用价值。,0
Enhanced Diffusion Sampling via Extrapolation with Multiple ODE Solutions,通过多重ODE解的外推增强扩散采样,02 Apr 2025,Diffusion Model,Other,https://arxiv.org/pdf/2504.01855,https://www.arxiv.org/abs/2504.01855,https://www.alphaxiv.org/abs/2504.01855,本文提出了一种基于多重常微分方程（ODE）解的增强型扩散采样方法RX-DPM，以提高扩散概率模型（DPMs）的采样效率和样本质量。该方法借鉴了Richardson外推技术，通过在中间时间步骤利用多个ODE解来减少数值误差并加快收敛速度。与传统方法不同，RX-DPM允许灵活的时间步调度，从而优化采样过程。实验结果表明，该方法在不增加采样迭代次数的情况下，显著提升了生成样本的准确性和质量，增强了DPMs在实际应用中的可用性。,0
Is the Reversal Curse a Binding Problem? Uncovering Limitations of Transformers from a Basic Generalization Failure,逆转诅咒是一个绑定问题吗？揭示变压器的基本泛化失败的局限性,02 Apr 2025,LLM,Other,https://arxiv.org/pdf/2504.01928,https://www.arxiv.org/abs/2504.01928,https://www.alphaxiv.org/abs/2504.01928,本论文探讨了大型语言模型（LLMs）在学习可逆事实关联时所面临的基本泛化失败，称为“反转诅咒”。作者提出该问题可能源于认知科学中的长期绑定问题，具体表现为概念表示的不一致性和纠缠。通过实验，研究展示了一种基于联合嵌入预测架构（JEPA）的模型设计，能够在不依赖数据增强或非因果掩蔽的情况下突破反转诅咒。此外，加入特殊记忆层可进一步提升模型的泛化能力。这项研究为理解和改善LLMs的学习能力提供了新的视角。,0
An Approach to Technical AGI Safety and Security,通用人工智能安全与安全性的技术方法,02 Apr 2025,AGI,DeepMind,https://arxiv.org/pdf/2504.01849,https://www.arxiv.org/abs/2504.01849,https://www.alphaxiv.org/abs/2504.01849,这篇论文探讨了人工通用智能（AGI）在带来重大益处的同时也可能引发严重风险的问题。作者提出了一种应对AGI安全和安全性的技术性方法，重点关注四个风险领域：误用、误对齐、错误和结构性风险。为了防止误用，论文建议通过识别危险能力和实施安全措施来限制访问。为了解决误对齐问题，作者提出了模型层面和系统层面的防御策略，包括增强监督和访问控制。论文强调，技术解决方案应与有效的治理相结合，以建立AGI的安全标准和最佳实践，从而减少潜在的严重危害。,0
PaperBench: Evaluating AI's Ability to Replicate AI Research,PaperBench：评估人工智能复制人工智能研究的能力,02 Apr 2025,Agent,OpenAI,https://arxiv.org/pdf/2504.01848,https://www.arxiv.org/abs/2504.01848,https://www.alphaxiv.org/abs/2504.01848,"本文介绍了PaperBench，一个评估AI代理复制前沿AI研究能力的基准。PaperBench要求代理从零开始复制20篇2024年国际机器学习大会（ICML）的重点和口头论文，涉及理解论文贡献、开发代码库和执行实验。为确保评估的客观性，研究团队与每篇论文的作者共同制定了详细的评分标准，共计8,316个可评估任务。通过评估多种AI模型，发现最佳模型Claude 3.5 Sonnet的平均复制得分为21.0%，尚未超越人类专家的表现。该研究为理解AI在机器学习研究中的工程能力提供了基础，并开源了相关代码以促进未来研究。",0
TransientTables: Evaluating LLMs' Reasoning on Temporally Evolving Semi-structured Tables,瞬态表格：评估大语言模型在时间演变的半结构化表格上的推理能力,02 Apr 2025,LLM,Other,https://arxiv.org/pdf/2504.01879,https://www.arxiv.org/abs/2504.01879,https://www.alphaxiv.org/abs/2504.01879,本文介绍了TRANSIENT TABLES数据集，旨在评估大型语言模型（LLMs）在处理时间变化的半结构化表格信息方面的推理能力。数据集包含3971个问题，源自14000多个表格，覆盖1238个实体和多个时间段。研究者们提出了一种基于模板的问题生成方法，并利用先进的LLMs建立了基线结果。此外，论文还引入了任务分解的建模策略，以提升LLMs的表现。通过探索LLMs的时间推理能力，研究为其在动态信息处理中的应用提供了新视角。,0
