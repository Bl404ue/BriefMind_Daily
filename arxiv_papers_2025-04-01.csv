标题,中文标题,发布日期,领域分类,研究机构,PDF链接,论文链接,AlphaXiv链接,简明摘要,点赞数
Visual Acoustic Fields,视觉声场,31 Mar 2025,Other,Other,https://arxiv.org/pdf/2503.24270,https://www.arxiv.org/abs/2503.24270,https://www.alphaxiv.org/abs/2503.24270,本文提出了一种新颖的框架——视觉声场（Visual Acoustic Fields），旨在将视觉信号与3D场景中的声音信号结合起来。该框架利用3D高斯点云（3DGS）技术，实现了两个主要功能：基于视觉的声音生成和声音定位。通过条件扩散模型，框架能够根据物体的外观和材料生成逼真的撞击声，同时也能准确定位声音源。为支持这一框架，研究团队开发了一种新的数据收集管道，首次在3D环境中建立了视觉和声音信号的空间对齐数据集。实验结果表明，该方法在生成撞击声和定位声音源方面具有显著效果，推动了物体交互理解的研究。,1
HumanDreamer: Generating Controllable Human-Motion Videos via Decoupled Generation,HumanDreamer：通过解耦生成生成可控的人体运动视频,31 Mar 2025,Other,PKU,https://arxiv.org/pdf/2503.24026,https://www.arxiv.org/abs/2503.24026,https://www.alphaxiv.org/abs/2503.24026,论文《HumanDreamer: Generating Controllable Human-Motion Videos via Decoupled Generation》提出了一种新的框架，用于生成可控的人类运动视频。该方法将生成过程分为两个步骤：从文本生成姿势（Text-to-Pose）和从姿势生成视频（Pose-to-Video）。通过构建一个包含120万对文本-姿势的数据集（MotionVid），并引入新颖的LAMA损失函数，HumanDreamer显著提高了生成质量和准确性。实验表明，该框架能够生成多样化和高质量的人类运动视频，并可应用于其他相关任务，如姿势序列预测和2D-3D运动提升。,1
"ACPBench Hard: Unrestrained Reasoning about Action, Change, and Planning",ACPBench Hard: 关于行动、变化和规划的无约束推理,31 Mar 2025,Agent,Other,https://arxiv.org/pdf/2503.24378,https://www.arxiv.org/abs/2503.24378,https://www.alphaxiv.org/abs/2503.24378,"论文《ACPBench Hard: Unrestrained Reasoning about Action, Change, and Planning》介绍了一个新的数据集ACPBench Hard，旨在测试人工智能在行动、变化和规划方面的推理能力。与之前的ACPBench数据集相比，ACPBench Hard采用开放式生成问题，挑战模型在没有明确选项的情况下进行推理。研究显示，尽管当前大型语言模型在这些任务上表现不佳，大多数模型的得分仍低于65%。论文还提出了针对每个任务的评估算法，以验证答案的正确性，指出现有模型在规划推理方面仍需改进。该研究为理解和提升AI的推理与规划能力提供了重要的基准和方向。",0
Exploring the Effect of Reinforcement Learning on Video Understanding: Insights from SEED-Bench-R1,探索强化学习对视频理解的影响：来自SEED-Bench-R1的见解,31 Mar 2025,Agent,Tencent,https://arxiv.org/pdf/2503.24376,https://www.arxiv.org/abs/2503.24376,https://www.alphaxiv.org/abs/2503.24376,本论文探讨了强化学习（RL）在视频理解中的应用，提出了SEED-Bench-R1基准，旨在系统评估多模态大型语言模型（MLLMs）在复杂日常任务中的表现。通过设定三层评估层次，研究显示使用RL训练的模型在处理分布外任务时表现优于传统的监督微调（SFT）模型，特别是在视觉感知和推理能力方面。尽管RL提高了模型的表现，但仍存在推理链不一致和视觉线索遗漏等问题。研究为未来的模型改进提供了方向，强调了在多模态理解中强化学习的潜力和挑战。,0
Effectively Controlling Reasoning Models through Thinking Intervention,通过思维干预有效控制推理模型,31 Mar 2025,LLM,Other,https://arxiv.org/pdf/2503.24370,https://www.arxiv.org/abs/2503.24370,https://www.alphaxiv.org/abs/2503.24370,本论文提出了一种新颖的“思维干预”方法，旨在通过显式引导大型语言模型（LLMs）的内部推理过程，提升其在复杂任务中的表现。与传统的提示工程不同，思维干预通过在推理过程中插入或修改特定的思维标记，实现对模型行为的精细控制。研究结果表明，该方法在多个任务中显著超越了基线提示方法，尤其在指令遵循、指令层次和安全性对齐方面，准确率提高了6.7%至40%。这一研究为更有效地控制推理模型开辟了新的研究方向。,0
"What, How, Where, and How Well? A Survey on Test-Time Scaling in Large Language Models",什么、如何、在哪里以及效果如何？关于大语言模型测试时间扩展的调查,31 Mar 2025,LLM,Other,https://arxiv.org/pdf/2503.24235,https://www.arxiv.org/abs/2503.24235,https://www.alphaxiv.org/abs/2503.24235,本文对测试时扩展（TTS）在大型语言模型（LLMs）中的应用进行了全面调查，提出了一个统一的多维框架，涵盖了“什么、如何、在哪里以及效果如何”等四个核心维度。研究表明，TTS能够显著提升LLMs在各种任务中的表现，包括数学和编程等专业推理任务以及开放式问答。该框架不仅系统地分析了现有方法和应用场景，还提供了未来研究的指导，识别了当前面临的挑战和潜在的发展方向。这项工作为理解和部署TTS提供了结构化的视角，促进了该领域的理论和实践进步。,0
Towards Scientific Intelligence: A Survey of LLM-based Scientific Agents,迈向科学智能：基于大语言模型的科学智能体调查,31 Mar 2025,Agent,Other,https://arxiv.org/pdf/2503.24047,https://www.arxiv.org/abs/2503.24047,https://www.alphaxiv.org/abs/2503.24047,本文综述了基于大语言模型（LLM）的科学智能代理，探讨其在现代科学研究中的应用与挑战。随着科学研究的复杂性增加，这些专门的代理能够自动化关键任务，如假设生成、实验设计和数据分析，整合领域特定知识和工具，处理复杂数据类型。与通用LLM不同，科学代理确保了研究的可重复性和伦理性，推动科学突破。本文提供了对这些代理架构、设计、应用及伦理考量的全面回顾，为研究人员和实践者提供了有效利用这些工具的路线图。,0
Rubric Is All You Need: Enhancing LLM-based Code Evaluation With Question-Specific Rubrics,只需评分标准：通过问题特定评分标准增强基于LLM的代码评估,31 Mar 2025,LLM,Other,https://arxiv.org/pdf/2503.23989,https://www.arxiv.org/abs/2503.23989,https://www.alphaxiv.org/abs/2503.23989,本论文探讨了使用大型语言模型（LLM）进行代码评估的挑战，并提出了通过问题特定评分标准来提升评估效果的方法。研究中引入了两个新数据集，分别涵盖数据结构与算法和面向对象编程的学生提交作品。作者提出了一种新的评估指标“宽容度”，以量化评估的严格性。结果表明，问题特定的评分标准在逻辑评估方面显著优于传统的无关评分标准，能够提供更符合教学目标的反馈，从而改善计算机教育中的代码评估过程。,0
SchemaAgent: A Multi-Agents Framework for Generating Relational Database Schema,SchemaAgent：用于生成关系数据库模式的多智能体框架,31 Mar 2025,Agent,Other,https://arxiv.org/pdf/2503.23886,https://www.arxiv.org/abs/2503.23886,https://www.alphaxiv.org/abs/2503.23886,本文提出了SchemaAgent，一个基于大语言模型的多代理框架，用于自动生成高质量的关系数据库模式。该框架通过模拟手动设计流程，分配专门角色给各个代理，以有效协作完成不同子任务，并引入反思和检查角色来识别和纠正错误。与现有的基于规则或传统深度学习模型的方法相比，SchemaAgent在生成数据库模式时表现出更优的效果。研究还提供了一个名为RSchema的基准数据集，以评估该方法的有效性，实验结果显示其优于主流的大语言模型。,0
RIG: Synergizing Reasoning and Imagination in End-to-End Generalist Policy,RIG：在端到端通用政策中协同推理与想象,31 Mar 2025,Embodied AI,Shanghai AI Lab,https://arxiv.org/pdf/2503.24388,https://www.arxiv.org/abs/2503.24388,https://www.alphaxiv.org/abs/2503.24388,本文提出了一种名为RIG的端到端通用策略，旨在将推理和想象能力结合，以提升智能体在复杂开放世界环境中的表现。与以往仅使用单一能力或将多种模型组合的方式不同，RIG通过逐步整合推理和想象的内容，显著提高了样本效率和泛化能力。实验结果表明，RIG在推理下一步行动、生成潜在行动及预测结果的过程中，能够自我修正，从而增强了智能体的鲁棒性和性能。此研究为智能体在动态环境中的决策提供了新的思路。,0
Open-Reasoner-Zero: An Open Source Approach to Scaling Up Reinforcement Learning on the Base Model,Open-Reasoner-Zero：一种开源方法以扩展基础模型上的强化学习,31 Mar 2025,Agent,THU,https://arxiv.org/pdf/2503.24290,https://www.arxiv.org/abs/2503.24290,https://www.alphaxiv.org/abs/2503.24290,本文介绍了Open-Reasoner-Zero，这是首个开源的大规模推理导向强化学习（RL）训练实现，旨在提高可扩展性、简便性和可访问性。通过实验，研究表明，使用简单的PPO算法和规则基础奖励即可显著提升模型在多个基准任务（如AIME2024、MATH500和GPQA Diamond）的表现，同时训练步骤仅为DeepSeek-R1-Zero的十分之一。该研究提供了详细的训练策略和应对常见挑战的见解，旨在使先进的RL训练技术对更广泛的研究社区开放。,0
Easi3R: Estimating Disentangled Motion from DUSt3R Without Training,Easi3R：无训练情况下从DUSt3R估计解耦运动,31 Mar 2025,Other,Other,https://arxiv.org/pdf/2503.24391,https://www.arxiv.org/abs/2503.24391,https://www.alphaxiv.org/abs/2503.24391,论文提出了Easi3R，一种无需训练的4D重建方法，旨在从动态视频中高效地估计物体和相机运动。与传统方法依赖大量训练数据和几何先验不同，Easi3R利用DUSt3R中的注意力机制，直接在推理阶段进行适应，成功实现动态区域分割、相机姿态估计和密集点云重建。实验结果表明，Easi3R在处理动态视频时显著优于现有的基于训练的方法，展示了其在计算机视觉领域的潜在应用价值。,0
Can Test-Time Scaling Improve World Foundation Model?,测试时缩放能否改善世界基础模型？,31 Mar 2025,Embodied AI,Other,https://arxiv.org/pdf/2503.24320,https://www.arxiv.org/abs/2503.24320,https://www.alphaxiv.org/abs/2503.24320,本文提出了SWIFT，一个专为世界基础模型（WFM）设计的测试时间缩放框架，旨在提升模型推理性能而无需增加模型规模或重新训练。WFM在模拟物理世界和支持自主驾驶、机器人等应用中发挥重要作用，但其训练和推理面临高计算需求和数据限制。SWIFT结合了快速标记、概率基础的Top-K剪枝和高效的束搜索策略，提供了一个模块化的评估工具包，支持多方面的评估。实验证明，SWIFT有效提升了WFM的推理效果，为WFM的应用提供了新的思路和方法。,0
Training-Free Text-Guided Image Editing with Visual Autoregressive Model,无训练的文本引导图像编辑与视觉自回归模型,31 Mar 2025,Other,Other,https://arxiv.org/pdf/2503.23897,https://www.arxiv.org/abs/2503.23897,https://www.alphaxiv.org/abs/2503.23897,本论文提出了一种基于视觉自回归模型（VAR）的无训练文本引导图像编辑框架，旨在解决现有方法中图像编辑的准确性和控制性问题。该方法不依赖于显式反演，采用缓存机制存储原始图像的标记索引和概率分布，从而实现精确的局部修改。通过动态识别和限制相关区域的编辑，该框架有效避免了不必要的图像变化。实验结果表明，该方法在编辑速度和视觉质量上优于现有的扩散模型和修正流技术，处理1080p图像的速度可达1.2秒，展现出高保真度和多样性。,0
Better wit than wealth: Dynamic Parametric Retrieval Augmented Generation for Test-time Knowledge Enhancement,智慧胜于财富：动态参数检索增强生成用于测试时知识增强,31 Mar 2025,LLM,Other,https://arxiv.org/pdf/2503.23895,https://www.arxiv.org/abs/2503.23895,https://www.alphaxiv.org/abs/2503.23895,本文提出了一种新颖的动态参数化检索增强生成框架（DyPRAG），旨在提高大型语言模型（LLMs）在测试时的知识增强能力。DyPRAG通过轻量级参数转换模型将外部文档有效转化为模型参数，解决了传统检索增强生成（RAG）方法中高推理成本和知识冲突（即RAG幻觉）的问题。与现有的参数化RAG（PRAG）相比，DyPRAG显著降低了训练和存储成本，同时提高了模型的泛化能力。实验结果表明，DyPRAG在多个数据集上表现出色，为知识融合和实际应用中的信息准确性提供了有效解决方案。,0
Optimal Transport-Guided Source-Free Adaptation for Face Anti-Spoofing,基于最优传输的无源适应面部反欺诈方法,29 Mar 2025,Other,Amazon,https://arxiv.org/pdf/2503.22984,https://www.arxiv.org/abs/2503.22984,https://www.alphaxiv.org/abs/2503.22984,本论文提出了一种新颖的方法，通过最优传输引导的源无关适应技术，解决面部反欺诈模型在不同用户测试数据中的适应性问题。该方法允许客户端在测试时仅使用少量数据自适应目标领域，而无需访问模型参数或训练数据。研究中开发的原型基础模型和适应器可以在轻量训练或无训练的情况下进行适应，同时引入了基于最优传输的地质混合技术，以生成增强训练数据。这种方法在跨领域和跨攻击设置中，相较于现有方法，平均提高了19.17%的错误识别率和8.58%的AUC，展示了其在隐私保护和快速定制服务中的潜力。,0
L0-Reasoning Bench: Evaluating Procedural Correctness in Language Models via Simple Program Execution,L0-推理基准：通过简单程序执行评估语言模型的程序正确性,28 Mar 2025,LLM,Other,https://arxiv.org/pdf/2503.22832,https://www.arxiv.org/abs/2503.22832,https://www.alphaxiv.org/abs/2503.22832,本文提出了L0-Bench，一个用于评估语言模型在程序执行中保持程序正确性的基准测试。研究强调了“零级推理”能力，即在多个步骤中准确执行简单规则的重要性。L0-Bench通过合成Python程序，系统地评估模型生成无误执行轨迹的能力，填补了现有基准主要关注结果正确性的空白。实验结果显示，尽管所有模型在目标执行步骤增加时表现下降，但较大和增强推理能力的模型在多个步骤中更能保持正确性。该研究为提高语言模型的推理能力和可靠性提供了重要方向。,0
Any2Caption:Interpreting Any Condition to Caption for Controllable Video Generation,Any2Caption：解释任意条件以进行可控视频生成,31 Mar 2025,Multimodal LLM,Other,https://arxiv.org/pdf/2503.24379,https://www.arxiv.org/abs/2503.24379,https://www.alphaxiv.org/abs/2503.24379,论文《Any2Caption》提出了一种新颖的框架，用于在多种条件下实现可控视频生成。该框架通过解耦条件解释和视频合成步骤，利用现代多模态大语言模型，将文本、图像和视频等多种输入转化为结构化的密集字幕，从而更好地引导视频生成器。研究还介绍了一个包含337K实例和407K条件的大规模数据集，用于优化指令调优。实验结果表明，Any2Caption在可控性和视频质量方面显著优于现有模型，为视频生成领域的用户意图理解提供了有效解决方案。,0
Enhancing Image Resolution of Solar Magnetograms: A Latent Diffusion Model Approach,增强太阳磁图像分辨率：一种潜在扩散模型方法,31 Mar 2025,Diffusion Model,Other,https://arxiv.org/pdf/2503.24271,https://www.arxiv.org/abs/2503.24271,https://www.alphaxiv.org/abs/2503.24271,"本研究提出了一种新颖的潜在扩散模型（LDM）方法，用于提高太阳磁图像的分辨率，尤其是来自老旧的Michelson Doppler Imager（MDI）数据。通过对下采样的Helioseismic and Magnetic Imager（HMI）数据进行训练，并与MDI/HMI配对数据进行微调，研究人员成功将MDI图像的分辨率从2""/像素提升至0.5""/像素。评估结果显示，重建图像在质量和物理特性（如无符号磁通和活动区大小）上得到了良好保留。本研究为太阳物理研究提供了更高分辨率的数据，有助于深入理解太阳内部和大气的物理过程。",0
Learning a Canonical Basis of Human Preferences from Binary Ratings,从二元评分中学习人类偏好的标准基,31 Mar 2025,Other,Other,https://arxiv.org/pdf/2503.24150,https://www.arxiv.org/abs/2503.24150,https://www.alphaxiv.org/abs/2503.24150,本文提出了一种方法来理解和分类人类偏好，重点分析二元选择数据集中的偏好。研究发现，21个偏好类别能够捕捉超过89%的个体偏好变异，这些类别构成了人类偏好的“标准基”。通过合成和实证评估，作者验证了这一低秩偏好集的广泛适用性，并展示了其在模型评估和训练中的实用性，能够更有效地与用户偏好对齐。研究结果及相关数据集已公开发布，推动了人类偏好理解与生成模型对齐的研究。,0
Learning 3D-Gaussian Simulators from RGB Videos,从RGB视频学习3D高斯模拟器,31 Mar 2025,Other,Other,https://arxiv.org/pdf/2503.24009,https://www.arxiv.org/abs/2503.24009,https://www.alphaxiv.org/abs/2503.24009,本文介绍了一种名为3DGSim的3D物理模拟器，它能够从多视角RGB视频中学习物体动态。3DGSim通过将图像编码为3D高斯粒子表示，利用变换器传播动力学，并通过3D高斯渲染生成帧。该模型在不强制连接约束的情况下，能够嵌入物理特性，捕捉从刚性到弹性及布料等多种物理行为，同时实现真实的光照效果。3DGSim的设计提高了物理准确性，具备更好的可扩展性和泛化能力，适用于未见的多体交互和新场景编辑，展示了在机器人决策中的潜在应用价值。,0
PAARS: Persona Aligned Agentic Retail Shoppers,PAARS: 人格对齐的自主零售购物者,31 Mar 2025,Agent,Amazon,https://arxiv.org/pdf/2503.24228,https://www.arxiv.org/abs/2503.24228,https://www.alphaxiv.org/abs/2503.24228,本论文提出了PAARS框架，旨在通过生成个性化的购物代理来模拟人类消费者行为，以提高电子商务中的决策效率。该框架利用匿名历史购物数据自动挖掘用户个性，赋予代理零售特定工具，并引入了一种新的行为对齐评估方法，关注群体级别的表现差异。实验结果表明，使用个性化代理能够提高对齐性能，尽管与人类行为仍存在差距。该研究为自动化A/B测试提供了初步应用，并讨论了未来在零售及其他领域的潜在应用和挑战。,0
Navi-plus: Managing Ambiguous GUI Navigation Tasks with Follow-up,Navi-plus: 通过后续问题管理模糊的GUI导航任务,31 Mar 2025,Agent,Other,https://arxiv.org/pdf/2503.24180,https://www.arxiv.org/abs/2503.24180,https://www.alphaxiv.org/abs/2503.24180,本文提出了一种新的图形用户界面（GUI）导航任务——自我纠正GUI导航，旨在解决用户在描述任务时可能遗漏关键信息的问题。研究团队开发了Navi-plus数据集，其中包含GUI跟进问答对，并引入了一种双流轨迹评估方法来评估这一新能力。实验结果表明，具备提出跟进问题能力的GUI代理在面对模糊任务时，能够恢复超过99.4%的性能。这项研究为提升GUI代理在复杂任务中的有效性提供了新思路，增强了人机交互的灵活性和准确性。,0
