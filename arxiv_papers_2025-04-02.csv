标题,中文标题,发布日期,领域分类,研究机构,PDF链接,论文链接,AlphaXiv链接,简明摘要,点赞数
Harnessing the Reasoning Economy: A Survey of Efficient Reasoning for Large Language Models,利用推理经济：大语言模型高效推理的调查,31 Mar 2025,LLM,Other,https://arxiv.org/pdf/2503.24377,https://www.arxiv.org/abs/2503.24377,https://www.alphaxiv.org/abs/2503.24377,本文综述了大型语言模型（LLMs）在推理效率方面的研究，提出了“推理经济”的概念，以平衡推理性能与计算成本。虽然深度推理（系统2）提高了任务准确性，但常常伴随高计算开销，而快速推理（系统1）则效率较高但效果不佳。论文分析了推理低效的原因、不同推理模式的行为，并探讨了在后训练和测试阶段实现推理经济的潜在解决方案。通过提供可操作的见解和开放挑战，旨在推动该领域的研究进展，并建立了一个公共资源库以跟踪相关发展。,7
Self-Routing RAG: Binding Selective Retrieval with Knowledge Verbalization,自路由RAG：结合选择性检索与知识表述,01 Apr 2025,LLM,Other,https://arxiv.org/pdf/2504.01018,https://www.arxiv.org/abs/2504.01018,https://www.alphaxiv.org/abs/2504.01018,"本文提出了一种新颖的框架——自路由检索增强生成（Self-Routing RAG, SR-RAG），旨在提升选择性检索的效果。SR-RAG结合了外部知识检索与大型语言模型（LLM）自身知识的口头表达，允许模型动态选择最合适的知识源。通过多任务优化，SR-RAG显著提高了响应的准确性和推理效率，减少了29%的检索需求，同时提升了5.1%的性能。该方法在复杂查询中表现尤为出色，展示了知识口头表达在选择性检索中的重要性。数据和代码将公开发布，以促进后续研究。",0
"When To Solve, When To Verify: Compute-Optimal Problem Solving and Generative Verification for LLM Reasoning",何时求解，何时验证：计算最优的问题解决与大语言模型推理的生成验证,01 Apr 2025,LLM,Google,https://arxiv.org/pdf/2504.01005,https://www.arxiv.org/abs/2504.01005,https://www.alphaxiv.org/abs/2504.01005,本论文探讨了在有限推理预算下，如何优化大型语言模型（LLMs）的问题解决与验证过程。研究比较了两种方法：自一致性（SC）和生成奖励模型（GenRM）。结果表明，在大多数实际预算下，自一致性在计算效率上优于生成奖励模型，尤其在低预算时，SC使用的计算资源最多可减少8倍。尽管GenRM在高预算下表现更佳，但整体上，研究提供了在测试时间优化中平衡解题生成与验证的实用指导，为提升LLMs的推理能力提供了新的视角。,0
MedReason: Eliciting Factual Medical Reasoning Steps in LLMs via Knowledge Graphs,MedReason：通过知识图谱引导大语言模型中的事实医学推理步骤,01 Apr 2025,LLM,Other,https://arxiv.org/pdf/2504.00993,https://www.arxiv.org/abs/2504.00993,https://www.alphaxiv.org/abs/2504.00993,"本文介绍了MedReason，一个大型高质量的医学推理数据集，旨在提升大型语言模型（LLMs）在医学领域的推理能力。通过利用结构化的医学知识图谱，MedReason将临床问答对转化为逻辑推理链，生成32,682个带有详细逐步解释的问题-回答对。实验表明，使用该数据集进行微调显著提高了医学问题解决能力，MedReason -8B模型在临床基准测试MedBullets中超越了现有的顶尖模型。该研究为提升AI在医学领域的可靠性和可解释性提供了重要支持。",0
On the Robustness of Agentic Function Calling,智能体功能调用的鲁棒性研究,01 Apr 2025,Agent,Other,https://arxiv.org/pdf/2504.00914,https://www.arxiv.org/abs/2504.00914,https://www.alphaxiv.org/abs/2504.00914,本文探讨了大型语言模型（LLMs）作为自主代理在功能调用（FC）方面的鲁棒性，提出了一个新基准来评估其对自然语言查询变体的韧性及在工具包扩展时的稳定性。尽管已有研究主要关注FC的准确性，但对其鲁棒性的研究相对较少。通过对现有FC模型在伯克利功能调用排行榜（BFCL）上的表现进行评估，论文揭示了当前评估方法的关键弱点，并指出在实际应用中改进的必要性。这项研究为未来的LLM代理部署提供了重要的见解和改进方向。,0
Agent S2: A Compositional Generalist-Specialist Framework for Computer Use Agents,Agent S2：一种用于计算机使用智能体的组合通用-专业框架,01 Apr 2025,Agent,Other,https://arxiv.org/pdf/2504.00906,https://www.arxiv.org/abs/2504.00906,https://www.alphaxiv.org/abs/2504.00906,本文介绍了Agent S2，一个新颖的计算机使用代理框架，旨在提高数字任务的自动化效率。Agent S2通过将认知任务分配给不同的通用模型和专业模型，解决了当前代理在GUI元素定位、长时间任务规划和性能瓶颈等方面的挑战。该框架采用了新颖的混合定位技术和主动层级规划方法，能够动态调整行动计划。实验结果表明，Agent S2在多个计算机使用基准测试中达到了新的最优性能，尤其在OSWorld基准的15步和50步评估中，分别提高了18.9%和32.7%。该系统展示了在多种操作系统和应用程序中的有效推广能力。,0
GenPRM: Scaling Test-Time Compute of Process Reward Models via Generative Reasoning,GenPRM：通过生成推理扩展过程奖励模型的测试时间计算,01 Apr 2025,LLM,"THU, Shanghai AI Lab",https://arxiv.org/pdf/2504.00891,https://www.arxiv.org/abs/2504.00891,https://www.alphaxiv.org/abs/2504.00891,本文提出了GenPRM，一种生成式过程奖励模型，旨在提升大语言模型（LLMs）的过程监督能力。GenPRM通过显式的链式推理和代码验证，解决了现有过程奖励模型（PRMs）在监督能力、泛化和测试时间计算方面的局限性。研究中引入了相对进度估计和新颖的推理框架，显著提高了模型的性能。实验结果表明，GenPRM在多个数学推理任务和ProcessBench上优于传统的分类基础PRMs，且较小的GenPRM模型在测试时间扩展中表现优异。这项研究为过程监督提供了新的视角，并为未来的研究指明了方向。,0
Improved Visual-Spatial Reasoning via R1-Zero-Like Training,通过R1-Zero类训练改善视觉空间推理,01 Apr 2025,Multimodal LLM,Other,https://arxiv.org/pdf/2504.00883,https://www.arxiv.org/abs/2504.00883,https://www.alphaxiv.org/abs/2504.00883,本论文探讨了通过R1-Zero-like训练提升多模态大型语言模型（MLLMs）在视频基础视觉空间推理（VSI）方面的能力。研究发现，传统的推理提示无法有效激活中小型Qwen2-VL模型的视觉空间推理能力，因此引入了基于GRPO的训练方法，并使用VSI-100k数据集进行优化。经过120小时的GPU训练，vsGRPO-2B模型在性能上超越了基础模型12.1%，而vsGRPO-7B模型则与最先进的开源模型LLaVA-NeXT-Video-72B相当。研究表明，GRPO训练在提升视觉空间推理方面具有显著优势，为未来的AI应用提供了新的思路和方法。,0
m1: Unleash the Potential of Test-Time Scaling for Medical Reasoning with Large Language Models,m1：释放大语言模型在医学推理中的测试时间缩放潜力,01 Apr 2025,LLM,Amazon,https://arxiv.org/pdf/2504.00869,https://www.arxiv.org/abs/2504.00869,https://www.alphaxiv.org/abs/2504.00869,本论文探讨了测试时间扩展（test-time scaling）在医学推理中的应用，提出了一种名为m1的有效方法，旨在提高大型语言模型（LLMs）的医学推理能力。研究表明，通过增加推理令牌预算，m1模型在多个医学问答任务中表现出显著的性能提升，尤其是32B模型的表现可与70B规模的医学LLMs相媲美。论文还发现，最佳推理令牌预算约为4K，超出此范围可能导致性能下降。此外，模型的医学知识不足被识别为性能提升的主要瓶颈，强调了在医学推理中，丰富的医学知识比单纯增加推理深度更为重要。,0
Investigating Large Language Models in Diagnosing Students' Cognitive Skills in Math Problem-solving,研究大语言模型在诊断学生数学问题解决中的认知技能,01 Apr 2025,LLM,Other,https://arxiv.org/pdf/2504.00843,https://www.arxiv.org/abs/2504.00843,https://www.alphaxiv.org/abs/2504.00843,本论文探讨了大型语言模型（LLMs）在数学问题解决中诊断学生认知技能的能力。研究构建了一个名为MATHCOG的新基准数据集，包含639个学生对110个中学数学问题的回应，并提供了详细的教师诊断。通过评估16种不同的LLMs，结果显示即使是最先进的模型在此任务中的表现依然欠佳，F1分数均低于0.5，并表现出对错误案例的过度自信。此外，模型规模与诊断性能呈正相关。研究揭示了当前自动化认知技能诊断的挑战，并指出了未来改进的方向。,0
ScholarCopilot: Training Large Language Models for Academic Writing with Accurate Citations,ScholarCopilot：为学术写作训练大型语言模型以实现准确引用,01 Apr 2025,LLM,Other,https://arxiv.org/pdf/2504.00824,https://www.arxiv.org/abs/2504.00824,https://www.alphaxiv.org/abs/2504.00824,"本论文介绍了ScholarCopilot，一种旨在提升学术写作中文本生成和引用准确性的统一框架。与传统的检索增强生成（RAG）系统不同，ScholarCopilot通过动态生成检索令牌（[RET]），在写作过程中实时决定何时检索相关文献，从而实现更灵活和上下文相关的引用。这种方法显著提高了生成质量和引用准确性，在500,000篇arXiv论文的训练基础上，模型在学术写作样本中表现优于许多大型模型。人类研究也证实了其在引用回忆、写作效率和用户体验方面的优越性，展示了其在学术写作辅助中的有效性。",0
WikiVideo: Article Generation from Multiple Videos,WikiVideo: 从多个视频生成文章,01 Apr 2025,Multimodal LLM,Other,https://arxiv.org/pdf/2504.00939,https://www.arxiv.org/abs/2504.00939,https://www.alphaxiv.org/abs/2504.00939,本文介绍了WIKIVIDEO，一个新颖的基准任务，旨在从多个视频中自动生成高水平的维基百科风格文章，聚焦于现实事件如自然灾害和政治选举。当前的文章生成方法主要依赖文本，而视频理解则侧重于低级别场景分析。为此，作者提出了协作文章生成（CAG）方法，通过结合推理模型和视频语言模型，能够更高效地提取高层次语义信息。WIKIVIDEO包含52个事件和近400个相关视频，支持生成内容丰富且有据可依的文章，旨在提高信息的准确性和即时性，特别是在快速发展的新闻环境中。,0
AI Judges in Design: Statistical Perspectives on Achieving Human Expert Equivalence With Vision-Language Models,设计中的AI评审：实现与视觉-语言模型的人类专家等效的统计视角,01 Apr 2025,Multimodal LLM,Other,https://arxiv.org/pdf/2504.00938,https://www.arxiv.org/abs/2504.00938,https://www.alphaxiv.org/abs/2504.00938,本文探讨了利用视觉-语言模型（VLMs）在工程设计中实现与人类专家评估等效的可能性。传统的设计评估依赖于人类专家，但过程繁琐且存在不一致性。研究提出了一种统计框架，用于评估AI评审者与人类专家的评分一致性。通过案例研究，结果显示，采用文本和图像结合推理的AI评审者在独特性和绘图质量上达到了专家级一致性，并在所有评估指标上超越或匹配了受过训练的初学者。这一发现表明，支持推理的VLM模型在设计评估中具有广泛应用潜力，为其他需要主观内容评估的领域提供了验证AI评审者的通用框架。,0
WISE-TTT:Worldwide Information Segmentation Enhancement,WISE-TTT：全球信息分割增强,01 Apr 2025,Other,Other,https://arxiv.org/pdf/2504.00879,https://www.arxiv.org/abs/2504.00879,https://www.alphaxiv.org/abs/2504.00879,本论文提出了WISE-TTT，一个结合了测试时训练（TTT）机制和Transformer架构的视频多目标分割新框架。该方法通过系统压缩历史时间数据，生成包含全球信息的隐藏状态，从而提升了长序列的上下文捕捉能力。实验结果表明，WISE-TTT在Davis2017长期基准测试中提高了3.1%的准确率，证明了跨网络层实现全球信息的重要性。该研究为解决视频分割中的长程依赖问题提供了新的思路，并为下一代跟踪系统奠定了基础。,0
Z1: Efficient Test-time Scaling with Code,Z1：基于代码的高效测试时间扩展,01 Apr 2025,LLM,THU,https://arxiv.org/pdf/2504.00810,https://www.arxiv.org/abs/2504.00810,https://www.alphaxiv.org/abs/2504.00810,本文提出了一种高效的测试时间扩展方法Z1，通过对大型语言模型（LLMs）进行代码相关推理轨迹的训练，减少了模型在解决复杂问题时的思维令牌消耗。我们创建了Z1-Code-Reasoning-107K数据集，包含107K个简单和复杂的编码问题及其推理轨迹，并引入了“Shifted Thinking Window”机制，以优化推理过程。经过训练的模型Z1-7B在多个推理任务上表现出与其他模型相当的性能，同时显著降低了思维令牌的使用，展示了良好的推理能力和广泛的任务适应性。这一研究为未来的高效推理提供了重要的见解。,0
Do We Truly Need So Many Samples? Multi-LLM Repeated Sampling Efficiently Scale Test-Time Compute,我们真的需要这么多样本吗？多LLM重复采样有效地扩展测试时计算,01 Apr 2025,LLM,Shanghai AI Lab,https://arxiv.org/pdf/2504.00762,https://www.arxiv.org/abs/2504.00762,https://www.alphaxiv.org/abs/2504.00762,本论文提出了一种新颖的策略，旨在通过重复采样和多模型结合来提高大语言模型（LLM）的性能和计算效率。通过引入多个模型（即使是较弱的模型），该策略能够充分利用不同模型在训练数据和方法上的互补优势。研究表明，模型生成答案的一致性与其准确性呈正相关，因此在生成过程中动态切换模型，以减少计算成本并提高答案的正确性。实验结果显示，该方法不仅优于现有的自一致性和多代理辩论方法，还显著降低了推理成本，展现了在生成-验证范式中利用多个LLM的潜力。,0
Inference-Time Scaling for Complex Tasks: Where We Stand and What Lies Ahead,复杂任务的推理时间扩展：我们所处的位置与未来展望,31 Mar 2025,LLM,Microsoft,https://arxiv.org/pdf/2504.00294,https://www.arxiv.org/abs/2504.00294,https://www.alphaxiv.org/abs/2504.00294,本论文探讨了推理时间扩展对大型语言模型（LLMs）在复杂任务中的影响，特别是在逐步解决问题的能力上。研究比较了九种最先进模型在八项挑战性任务（如数学推理、日历规划和导航等）中的表现，发现推理时间扩展的优势因任务而异且在问题复杂性增加时减弱。虽然增加生成的标记数量并不总能提高准确性，但在使用完美验证器或强反馈时，所有模型都显示出显著的性能提升潜力。这项研究为未来改进推理系统提供了宝贵的见解。,0
Large Language Models in Numberland: A Quick Test of Their Numerical Reasoning Abilities,数字王国中的大语言模型：对其数值推理能力的快速测试,31 Mar 2025,LLM,OpenAI,https://arxiv.org/pdf/2504.00226,https://www.arxiv.org/abs/2504.00226,https://www.alphaxiv.org/abs/2504.00226,本论文介绍了“Numberland”测试，旨在评估大型语言模型（LLMs）的数字推理能力。研究通过100道题目，包括基本运算、复杂计算和需要试错的24游戏，评估了五种LLM代理的表现。结果显示，尽管这些模型在确定性任务中得分较高（74-95%），但在需要试错的24游戏中表现不佳（10-73%），揭示了它们在数字推理方面的脆弱性。这项研究强调了理解LLMs的数学能力及其局限性的重要性，以确保安全和有效的使用。,0
Shot-by-Shot: Film-Grammar-Aware Training-Free Audio Description Generation,逐镜头：电影语法感知的无训练音频描述生成,01 Apr 2025,Multimodal LLM,Other,https://arxiv.org/pdf/2504.01020,https://www.arxiv.org/abs/2504.01020,https://www.alphaxiv.org/abs/2504.01020,本论文提出了一种名为“Shot-by-Shot”的自动音频描述生成框架，旨在为电影和电视节目等编辑视频材料生成音频描述。该方法通过扩展相邻镜头的时间上下文，并结合电影语法元素（如镜头规模和线索结构），实现了无训练的音频描述生成。研究表明，该框架在多个基准测试中超越了以往的无训练方法，甚至在某些情况下优于经过微调的方法。此外，论文还引入了一种新的评估指标“动作评分”，以更好地评估生成音频描述的质量。这一创新为视障人士提供了更流畅的观看体验。,0
MixerMDM: Learnable Composition of Human Motion Diffusion Models,MixerMDM：可学习的人类动作扩散模型组合,01 Apr 2025,Diffusion Model,Other,https://arxiv.org/pdf/2504.01019,https://www.arxiv.org/abs/2504.01019,https://www.alphaxiv.org/abs/2504.01019,本论文提出了MixerMDM，一种首创的可学习模型组合技术，用于结合预训练的文本条件人类运动扩散模型。MixerMDM通过动态混合策略，能够根据生成条件自适应地结合不同模型的去噪过程，从而实现对个体和多人运动的精细控制。该方法不仅提高了生成的人类运动的质量，还扩展了运动生成的可能性，克服了现有方法在合并过程中的局限性。此外，论文还提出了一种新的评估技术，首次量化了生成运动与条件之间的对齐度，验证了MixerMDM在动态混合过程中的适应能力。,0
GeometryCrafter: Consistent Geometry Estimation for Open-world Videos with Diffusion Priors,GeometryCrafter：基于扩散先验的开放世界视频一致几何估计,01 Apr 2025,Diffusion Model,"THU, Tencent",https://arxiv.org/pdf/2504.01016,https://www.arxiv.org/abs/2504.01016,https://www.alphaxiv.org/abs/2504.01016,论文《GeometryCrafter》提出了一种新颖的方法，用于从开放世界视频中估计高质量且时间一致的点图。该方法克服了现有几何估计技术的局限性，利用变分自编码器（VAE）有效编码和解码三维坐标，避免了信息损失。GeometryCrafter通过视频扩散模型建模点图序列的分布，支持准确的3D/4D重建和相机参数估计。实验结果表明，该方法在3D精度、时间一致性和泛化能力方面达到了最先进的水平，为视频生成和编辑等应用提供了坚实基础。,0
AnimeGamer: Infinite Anime Life Simulation with Next Game State Prediction,AnimeGamer：具有下一游戏状态预测的无限动漫生活模拟,01 Apr 2025,Agent,Tencent,https://arxiv.org/pdf/2504.01014,https://www.arxiv.org/abs/2504.01014,https://www.alphaxiv.org/abs/2504.01014,论文《AnimeGamer: Infinite Anime Life Simulation with Next Game State Prediction》提出了一种新型的无限动漫生活模拟游戏，利用多模态大型语言模型（MLLMs）生成动态游戏状态。与以往只生成静态图像的方法不同，AnimeGamer能够创建包含角色动作和状态更新的动态动画片段，增强了游戏的沉浸感和连贯性。通过引入历史动画镜头作为上下文并预测后续镜头，AnimeGamer实现了更具一致性和互动性的游戏体验。该研究展示了生成模型在动漫游戏中的潜力，为玩家提供了与喜爱角色互动的全新方式。,0
IntrinsiX: High-Quality PBR Generation using Image Priors,IntrinsiX：基于图像先验的高质量PBR生成,01 Apr 2025,Other,Other,https://arxiv.org/pdf/2504.01008,https://www.arxiv.org/abs/2504.01008,https://www.alphaxiv.org/abs/2504.01008,论文介绍了IntrinsiX，一种基于文本描述生成高质量物理基础渲染（PBR）图像的方法。与传统的文本到图像模型不同，IntrinsiX直接生成包含反射率、粗糙度、金属度和法线的PBR图，克服了现有方法在图像分解中的模糊性。通过利用强大的图像先验和交叉内在注意力机制，模型能够同时生成多个PBR图，确保输出的语义一致性。研究表明，IntrinsiX在生成细节和泛化能力上超越了现有的内在图像分解方法，具有广泛的应用潜力，如重光照、编辑和场景纹理生成。,0
Accelerating drug discovery with Artificial: a whole-lab orchestration and scheduling system for self-driving labs,利用人工智能加速药物发现：自驾实验室的全实验室协调与调度系统,01 Apr 2025,Other,Other,https://arxiv.org/pdf/2504.00986,https://www.arxiv.org/abs/2504.00986,https://www.alphaxiv.org/abs/2504.00986,这篇论文探讨了自驾驶实验室在药物发现中的应用，提出了一种全面的实验室协调和调度系统，以解决复杂工作流程的管理和数据整合问题。通过自动化实验流程和集成AI驱动的决策支持，Artificial Inc.的系统能够实时协调仪器、机器人和人员，提高实验的效率和可重复性。此外，利用AI模型（如NVIDIA BioNeMo）进行分子相互作用预测，进一步加速了数据驱动的研究，推动了药物发现的进程。这一创新为传统药物开发方法带来了变革，提高了研究的精确性和效率。,0
Grounding Multimodal LLMs to Embodied Agents that Ask for Help with Reinforcement Learning,将多模态大语言模型与请求帮助的具身智能体结合，利用强化学习,01 Apr 2025,Multimodal LLM,Meta,https://arxiv.org/pdf/2504.00907,https://www.arxiv.org/abs/2504.00907,https://www.alphaxiv.org/abs/2504.00907,本论文提出了一种新方法，旨在提升具身智能体在处理模糊人类指令时的能力。研究团队引入了ASK-TO-ACT任务，要求智能体在家庭环境中根据模糊指令获取特定物品，并通过提出最少的澄清问题来消除歧义。通过将多模态大语言模型（MLLMs）作为视觉-语言-行动（VLA）策略，并采用在线强化学习进行微调，研究显示该方法显著优于现有基线，提升了任务执行的准确性和效率。这项工作为构建能够有效理解和互动的智能家居机器人奠定了基础。,0
Visual Environment-Interactive Planning for Embodied Complex-Question Answering,具身复杂问题回答的视觉环境交互规划,01 Apr 2025,Embodied AI,Other,https://arxiv.org/pdf/2504.00775,https://www.arxiv.org/abs/2504.00775,https://www.alphaxiv.org/abs/2504.00775,本研究针对复杂问题回答任务，提出了一种基于视觉环境交互的规划框架，旨在提升机器人理解和处理复杂人类问题的能力。与传统的一步规划方法不同，该框架采用多步规划，通过解析自然语言并结合视觉层次场景图，逐步明确问题意图。通过创建结构化语义空间，机器人能够在多个交互回合中优化其行动策略，最终生成准确的回答。实验表明，该方法在复杂任务中表现优异，且具备实际应用潜力，为人机交互的进展提供了新的思路。,0
Personality-Driven Decision-Making in LLM-Based Autonomous Agents,基于大语言模型的自主智能体中的个性驱动决策制定,01 Apr 2025,Agent,Other,https://arxiv.org/pdf/2504.00727,https://www.arxiv.org/abs/2504.00727,https://www.alphaxiv.org/abs/2504.00727,本论文探讨了在基于大型语言模型（LLM）的自主智能体中，个性驱动的决策制定方法。研究基于五因素OCEAN个性模型，提出了一种新颖的方法来测量和评估个性特征如何影响任务选择过程，包括规划、调度和决策。结果显示，个性特征显著影响智能体的任务选择模式，为设计高效的欺骗性智能体在网络防御中的应用提供了可行性。这一研究为智能体的自主决策机制提供了新的视角，强调了个性在决策过程中的重要性。,0
Command A: An Enterprise-Ready Large Language Model,Command A：一款企业级大型语言模型,01 Apr 2025,LLM,Other,https://arxiv.org/pdf/2504.00698,https://www.arxiv.org/abs/2504.00698,https://www.alphaxiv.org/abs/2504.00698,论文介绍了Command A，一种专为企业应用设计的大型语言模型，支持23种语言并具备高效的检索增强生成能力。Command A采用了新颖的混合架构，通过去中心化训练和自我优化算法，实现了卓越的性能和效率。与同类模型相比，Command A在多个企业相关任务和基准测试中表现出色，尤其在处理复杂业务流程时表现突出。该模型的训练和评估结果已向研究界公开，旨在推动社区的进一步探索与应用。,0
